From 95d9a633686c533656d647ae59635c3b77015337 Mon Sep 17 00:00:00 2001
From: Jimmy Xiang <jxiang@cloudera.com>
Date: Fri, 9 Nov 2012 16:32:45 -0800
Subject: [PATCH 032/202] HBASE-7130 NULL qualifier is ignored

Reason: Bug
Author: Jimmy Xiang
Ref: CDH-8984
---
 .../java/org/apache/hadoop/hbase/client/Get.java   |    4 ++
 .../java/org/apache/hadoop/hbase/client/Scan.java  |    4 +-
 .../hbase/coprocessor/AggregateImplementation.java |   47 ++++++++++++++----
 .../hadoop/hbase/client/TestFromClientSide.java    |   52 ++++++++++++++++++++
 .../org/apache/hadoop/hbase/client/TestGet.java    |   10 ++++
 .../org/apache/hadoop/hbase/client/TestScan.java   |   10 ++++
 .../hbase/coprocessor/TestAggregateProtocol.java   |    2 -
 7 files changed, 116 insertions(+), 13 deletions(-)

diff --git a/src/main/java/org/apache/hadoop/hbase/client/Get.java b/src/main/java/org/apache/hadoop/hbase/client/Get.java
index 3f35cae..dc83d1d 100644
--- a/src/main/java/org/apache/hadoop/hbase/client/Get.java
+++ b/src/main/java/org/apache/hadoop/hbase/client/Get.java
@@ -20,6 +20,7 @@
 package org.apache.hadoop.hbase.client;
 
 import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hbase.HConstants;
 import org.apache.hadoop.hbase.KeyValue;
 import org.apache.hadoop.hbase.filter.Filter;
 import org.apache.hadoop.hbase.io.TimeRange;
@@ -131,6 +132,9 @@ public class Get extends OperationWithAttributes
     if(set == null) {
       set = new TreeSet<byte []>(Bytes.BYTES_COMPARATOR);
     }
+    if (qualifier == null) {
+      qualifier = HConstants.EMPTY_BYTE_ARRAY;
+    }
     set.add(qualifier);
     familyMap.put(family, set);
     return this;
diff --git a/src/main/java/org/apache/hadoop/hbase/client/Scan.java b/src/main/java/org/apache/hadoop/hbase/client/Scan.java
index 093c93b..96c9d6f 100644
--- a/src/main/java/org/apache/hadoop/hbase/client/Scan.java
+++ b/src/main/java/org/apache/hadoop/hbase/client/Scan.java
@@ -215,9 +215,11 @@ public class Scan extends OperationWithAttributes implements Writable {
     if(set == null) {
       set = new TreeSet<byte []>(Bytes.BYTES_COMPARATOR);
     }
+    if (qualifier == null) {
+      qualifier = HConstants.EMPTY_BYTE_ARRAY;
+    }
     set.add(qualifier);
     familyMap.put(family, set);
-
     return this;
   }
 
diff --git a/src/main/java/org/apache/hadoop/hbase/coprocessor/AggregateImplementation.java b/src/main/java/org/apache/hadoop/hbase/coprocessor/AggregateImplementation.java
index f6f4b42..5adf338 100644
--- a/src/main/java/org/apache/hadoop/hbase/coprocessor/AggregateImplementation.java
+++ b/src/main/java/org/apache/hadoop/hbase/coprocessor/AggregateImplementation.java
@@ -60,7 +60,11 @@ public class AggregateImplementation extends BaseEndpointCoprocessor implements
         .getRegion().getScanner(scan);
     List<KeyValue> results = new ArrayList<KeyValue>();
     byte[] colFamily = scan.getFamilies()[0];
-    byte[] qualifier = scan.getFamilyMap().get(colFamily).pollFirst();
+    NavigableSet<byte[]> qualifiers = scan.getFamilyMap().get(colFamily);
+    byte[] qualifier = null;
+    if (qualifiers != null && !qualifiers.isEmpty()) {
+      qualifier = qualifiers.pollFirst();
+    }
     // qualifier can be null.
     try {
       boolean hasMoreRows = false;
@@ -90,7 +94,11 @@ public class AggregateImplementation extends BaseEndpointCoprocessor implements
         .getRegion().getScanner(scan);
     List<KeyValue> results = new ArrayList<KeyValue>();
     byte[] colFamily = scan.getFamilies()[0];
-    byte[] qualifier = scan.getFamilyMap().get(colFamily).pollFirst();
+    NavigableSet<byte[]> qualifiers = scan.getFamilyMap().get(colFamily);
+    byte[] qualifier = null;
+    if (qualifiers != null && !qualifiers.isEmpty()) {
+      qualifier = qualifiers.pollFirst();
+    }
     try {
       boolean hasMoreRows = false;
       do {
@@ -119,7 +127,11 @@ public class AggregateImplementation extends BaseEndpointCoprocessor implements
     InternalScanner scanner = ((RegionCoprocessorEnvironment) getEnvironment())
         .getRegion().getScanner(scan);
     byte[] colFamily = scan.getFamilies()[0];
-    byte[] qualifier = scan.getFamilyMap().get(colFamily).pollFirst();
+    NavigableSet<byte[]> qualifiers = scan.getFamilyMap().get(colFamily);
+    byte[] qualifier = null;
+    if (qualifiers != null && !qualifiers.isEmpty()) {
+      qualifier = qualifiers.pollFirst();
+    }
     List<KeyValue> results = new ArrayList<KeyValue>();
     try {
       boolean hasMoreRows = false;
@@ -147,7 +159,11 @@ public class AggregateImplementation extends BaseEndpointCoprocessor implements
     long counter = 0l;
     List<KeyValue> results = new ArrayList<KeyValue>();
     byte[] colFamily = scan.getFamilies()[0];
-    byte[] qualifier = scan.getFamilyMap().get(colFamily).pollFirst();
+    NavigableSet<byte[]> qualifiers = scan.getFamilyMap().get(colFamily);
+    byte[] qualifier = null;
+    if (qualifiers != null && !qualifiers.isEmpty()) {
+      qualifier = qualifiers.pollFirst();
+    }
     if (scan.getFilter() == null && qualifier == null)
       scan.setFilter(new FirstKeyOnlyFilter());
     InternalScanner scanner = ((RegionCoprocessorEnvironment) getEnvironment())
@@ -178,7 +194,11 @@ public class AggregateImplementation extends BaseEndpointCoprocessor implements
     InternalScanner scanner = ((RegionCoprocessorEnvironment) getEnvironment())
         .getRegion().getScanner(scan);
     byte[] colFamily = scan.getFamilies()[0];
-    byte[] qualifier = scan.getFamilyMap().get(colFamily).pollFirst();
+    NavigableSet<byte[]> qualifiers = scan.getFamilyMap().get(colFamily);
+    byte[] qualifier = null;
+    if (qualifiers != null && !qualifiers.isEmpty()) {
+      qualifier = qualifiers.pollFirst();
+    }
     List<KeyValue> results = new ArrayList<KeyValue>();
     boolean hasMoreRows = false;
     try {
@@ -206,7 +226,11 @@ public class AggregateImplementation extends BaseEndpointCoprocessor implements
     InternalScanner scanner = ((RegionCoprocessorEnvironment) getEnvironment())
         .getRegion().getScanner(scan);
     byte[] colFamily = scan.getFamilies()[0];
-    byte[] qualifier = scan.getFamilyMap().get(colFamily).pollFirst();
+    NavigableSet<byte[]> qualifiers = scan.getFamilyMap().get(colFamily);
+    byte[] qualifier = null;
+    if (qualifiers != null && !qualifiers.isEmpty()) {
+      qualifier = qualifiers.pollFirst();
+    }
     List<KeyValue> results = new ArrayList<KeyValue>();
 
     boolean hasMoreRows = false;
@@ -241,10 +265,13 @@ public class AggregateImplementation extends BaseEndpointCoprocessor implements
     InternalScanner scanner = ((RegionCoprocessorEnvironment) getEnvironment())
     .getRegion().getScanner(scan);
     byte[] colFamily = scan.getFamilies()[0];
-    NavigableSet<byte[]> quals = scan.getFamilyMap().get(colFamily);
-    byte[] valQualifier = quals.pollFirst();
-    // if weighted median is requested, get qualifier for the weight column
-    byte[] weightQualifier = quals.size() > 1 ? quals.pollLast() : null;
+    NavigableSet<byte[]> qualifiers = scan.getFamilyMap().get(colFamily);
+    byte[] valQualifier = null, weightQualifier = null;
+    if (qualifiers != null && !qualifiers.isEmpty()) {
+      valQualifier = qualifiers.pollFirst();
+      // if weighted median is requested, get qualifier for the weight column
+      weightQualifier = qualifiers.pollLast();
+    }
     List<KeyValue> results = new ArrayList<KeyValue>();
 
     boolean hasMoreRows = false;
diff --git a/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java b/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java
index fc76f59..1fccb2b 100644
--- a/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java
+++ b/src/test/java/org/apache/hadoop/hbase/client/TestFromClientSide.java
@@ -3556,6 +3556,29 @@ public class TestFromClientSide {
   }
 
   @Test
+  public void testGet_NullQualifier() throws IOException {
+    HTable table = TEST_UTIL.createTable(Bytes.toBytes("testGet_NullQualifier"), FAMILY);
+    Put put = new Put(ROW);
+    put.add(FAMILY, QUALIFIER, VALUE);
+    table.put(put);
+
+    put = new Put(ROW);
+    put.add(FAMILY, null, VALUE);
+    table.put(put);
+    LOG.info("Row put");
+
+    Get get = new Get(ROW);
+    get.addColumn(FAMILY, null);
+    Result r = table.get(get);
+    assertEquals(1, r.size());
+
+    get = new Get(ROW);
+    get.addFamily(FAMILY);
+    r = table.get(get);
+    assertEquals(2, r.size());
+  }
+
+  @Test
   public void testGet_NonExistentRow() throws IOException {
     HTable table = TEST_UTIL.createTable(Bytes.toBytes("testGet_NonExistentRow"), FAMILY);
     Put put = new Put(ROW);
@@ -4858,6 +4881,35 @@ public class TestFromClientSide {
     assertEquals(1, bar.length);
   }
 
+  @Test
+  public void testScan_NullQualifier() throws IOException {
+    HTable table = TEST_UTIL.createTable(Bytes.toBytes("testScan_NullQualifier"), FAMILY);
+    Put put = new Put(ROW);
+    put.add(FAMILY, QUALIFIER, VALUE);
+    table.put(put);
+
+    put = new Put(ROW);
+    put.add(FAMILY, null, VALUE);
+    table.put(put);
+    LOG.info("Row put");
+
+    Scan scan = new Scan();
+    scan.addColumn(FAMILY, null);
+
+    ResultScanner scanner = table.getScanner(scan);
+    Result[] bar = scanner.next(100);
+    assertEquals(1, bar.length);
+    assertEquals(1, bar[0].size());
+
+    scan = new Scan();
+    scan.addFamily(FAMILY);
+
+    scanner = table.getScanner(scan);
+    bar = scanner.next(100);
+    assertEquals(1, bar.length);
+    assertEquals(2, bar[0].size());
+  }
+
   @org.junit.Rule
   public org.apache.hadoop.hbase.ResourceCheckerJUnitRule cu =
     new org.apache.hadoop.hbase.ResourceCheckerJUnitRule();
diff --git a/src/test/java/org/apache/hadoop/hbase/client/TestGet.java b/src/test/java/org/apache/hadoop/hbase/client/TestGet.java
index 93c59ef..9cf7ecf 100644
--- a/src/test/java/org/apache/hadoop/hbase/client/TestGet.java
+++ b/src/test/java/org/apache/hadoop/hbase/client/TestGet.java
@@ -27,6 +27,7 @@ import java.io.DataOutput;
 import java.io.DataOutputStream;
 import java.io.IOException;
 import java.util.Arrays;
+import java.util.Set;
 
 import org.apache.hadoop.hbase.SmallTests;
 import org.apache.hadoop.hbase.util.Bytes;
@@ -107,6 +108,15 @@ public class TestGet {
     Assert.assertNull(get.getAttributesMap().get("attribute1"));
   }
 
+  @Test
+  public void testNullQualifier() {
+    Get get = new Get(null);
+    byte[] family = Bytes.toBytes("family");
+    get.addColumn(family, null);
+    Set<byte[]> qualifiers = get.getFamilyMap().get(family);
+    Assert.assertEquals(1, qualifiers.size());
+  }
+
   @org.junit.Rule
   public org.apache.hadoop.hbase.ResourceCheckerJUnitRule cu =
     new org.apache.hadoop.hbase.ResourceCheckerJUnitRule();
diff --git a/src/test/java/org/apache/hadoop/hbase/client/TestScan.java b/src/test/java/org/apache/hadoop/hbase/client/TestScan.java
index cdb40bb..41003ed 100644
--- a/src/test/java/org/apache/hadoop/hbase/client/TestScan.java
+++ b/src/test/java/org/apache/hadoop/hbase/client/TestScan.java
@@ -27,6 +27,7 @@ import java.io.DataOutput;
 import java.io.DataOutputStream;
 import java.io.IOException;
 import java.util.Arrays;
+import java.util.Set;
 
 import org.apache.hadoop.hbase.SmallTests;
 import org.apache.hadoop.hbase.util.Bytes;
@@ -107,6 +108,15 @@ public class TestScan {
     Assert.assertNull(scan.getAttributesMap().get("attribute1"));
   }
 
+  @Test
+  public void testNullQualifier() {
+    Scan scan = new Scan();
+    byte[] family = Bytes.toBytes("family");
+    scan.addColumn(family, null);
+    Set<byte[]> qualifiers = scan.getFamilyMap().get(family);
+    Assert.assertEquals(1, qualifiers.size());
+  }
+
   @org.junit.Rule
   public org.apache.hadoop.hbase.ResourceCheckerJUnitRule cu =
     new org.apache.hadoop.hbase.ResourceCheckerJUnitRule();
diff --git a/src/test/java/org/apache/hadoop/hbase/coprocessor/TestAggregateProtocol.java b/src/test/java/org/apache/hadoop/hbase/coprocessor/TestAggregateProtocol.java
index 28af316..9c957fe 100644
--- a/src/test/java/org/apache/hadoop/hbase/coprocessor/TestAggregateProtocol.java
+++ b/src/test/java/org/apache/hadoop/hbase/coprocessor/TestAggregateProtocol.java
@@ -61,7 +61,6 @@ public class TestAggregateProtocol {
   private static byte[][] ROWS = makeN(ROW, ROWSIZE);
 
   private static HBaseTestingUtility util = new HBaseTestingUtility();
-  private static MiniHBaseCluster cluster = null;
   private static Configuration conf = util.getConfiguration();
 
   /**
@@ -76,7 +75,6 @@ public class TestAggregateProtocol {
         "org.apache.hadoop.hbase.coprocessor.AggregateImplementation");
 
     util.startMiniCluster(2);
-    cluster = util.getMiniHBaseCluster();
     HTable table = util.createTable(TEST_TABLE, TEST_FAMILY);
     util.createMultiRegions(util.getConfiguration(), table, TEST_FAMILY,
         new byte[][] { HConstants.EMPTY_BYTE_ARRAY, ROWS[rowSeperator1],
-- 
1.7.0.4

