From fd493de96be9bf48eefdc1bfa6452ae5b9917bab Mon Sep 17 00:00:00 2001
From: Namit Jain <namit@apache.org>
Date: Tue, 8 Jan 2013 18:19:59 +0000
Subject: [PATCH 193/218] CDH-13436:Back-port HIVE-3853.UDF unix_timestamp is deterministic if an argument is given, but it treated as non-deterministic preventing PPD

---
 .../hadoop/hive/ql/exec/FunctionRegistry.java      |    6 +-
 .../ql/udf/generic/GenericUDFToUnixTimeStamp.java  |  124 ++++++++++++++
 .../ql/udf/generic/GenericUDFUnixTimeStamp.java    |   36 ++++
 .../queries/clientpositive/udf_to_unix_timestamp.q |   29 +++
 .../queries/clientpositive/udf_unix_timestamp.q    |   11 +-
 .../results/clientpositive/show_functions.q.out    |    1 +
 ql/src/test/results/clientpositive/udf5.q.out      |    2 +-
 .../clientpositive/udf_to_unix_timestamp.q.out     |  180 ++++++++++++++++++++
 .../clientpositive/udf_unix_timestamp.q.out        |   43 +++--
 9 files changed, 409 insertions(+), 23 deletions(-)
 create mode 100644 ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToUnixTimeStamp.java
 create mode 100644 ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUnixTimeStamp.java
 create mode 100644 ql/src/test/queries/clientpositive/udf_to_unix_timestamp.q
 create mode 100644 ql/src/test/results/clientpositive/udf_to_unix_timestamp.q.out

diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java b/src/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java
index 4fe0866..4866a40 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java
@@ -124,7 +124,6 @@ import org.apache.hadoop.hive.ql.udf.UDFToString;
 import org.apache.hadoop.hive.ql.udf.UDFTrim;
 import org.apache.hadoop.hive.ql.udf.UDFType;
 import org.apache.hadoop.hive.ql.udf.UDFUnhex;
-import org.apache.hadoop.hive.ql.udf.UDFUnixTimeStamp;
 import org.apache.hadoop.hive.ql.udf.UDFUpper;
 import org.apache.hadoop.hive.ql.udf.UDFWeekOfYear;
 import org.apache.hadoop.hive.ql.udf.UDFYear;
@@ -202,9 +201,11 @@ import org.apache.hadoop.hive.ql.udf.generic.GenericUDFStruct;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFTimestamp;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFToBinary;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFToDecimal;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDFToUnixTimeStamp;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFToUtcTimestamp;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFTranslate;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFUnion;
+import org.apache.hadoop.hive.ql.udf.generic.GenericUDFUnixTimeStamp;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDFWhen;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDTF;
 import org.apache.hadoop.hive.ql.udf.generic.GenericUDTFExplode;
@@ -324,7 +325,6 @@ public final class FunctionRegistry {
     registerUDF("minute", UDFMinute.class, false);
     registerUDF("second", UDFSecond.class, false);
     registerUDF("from_unixtime", UDFFromUnixTime.class, false);
-    registerUDF("unix_timestamp", UDFUnixTimeStamp.class, false);
     registerUDF("to_date", UDFDate.class, false);
     registerUDF("weekofyear", UDFWeekOfYear.class, false);
 
@@ -470,6 +470,8 @@ public final class FunctionRegistry {
     registerGenericUDF("from_utc_timestamp", GenericUDFFromUtcTimestamp.class);
     registerGenericUDF("to_utc_timestamp", GenericUDFToUtcTimestamp.class);
 
+    registerGenericUDF("unix_timestamp", GenericUDFUnixTimeStamp.class);
+    registerGenericUDF("to_unix_timestamp", GenericUDFToUnixTimeStamp.class);
 
     // Generic UDTF's
     registerGenericUDTF("explode", GenericUDTFExplode.class);
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToUnixTimeStamp.java b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToUnixTimeStamp.java
new file mode 100644
index 0000000..e887552
--- /dev/null
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToUnixTimeStamp.java
@@ -0,0 +1,124 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hive.ql.udf.generic;
+
+import java.sql.Timestamp;
+import java.text.ParseException;
+import java.text.SimpleDateFormat;
+
+import org.apache.commons.lang.StringUtils;
+import org.apache.hadoop.hive.ql.exec.Description;
+import org.apache.hadoop.hive.ql.exec.UDFArgumentException;
+import org.apache.hadoop.hive.ql.exec.UDFArgumentLengthException;
+import org.apache.hadoop.hive.ql.metadata.HiveException;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;
+import org.apache.hadoop.hive.serde2.objectinspector.primitive.StringObjectInspector;
+import org.apache.hadoop.hive.serde2.objectinspector.primitive.TimestampObjectInspector;
+import org.apache.hadoop.io.LongWritable;
+
+/**
+ * deterministic version of UDFUnixTimeStamp. enforces argument
+ */
+@Description(name = "to_unix_timestamp",
+    value = "_FUNC_(date[, pattern]) - Returns the UNIX timestamp",
+    extended = "Converts the specified time to number of seconds since 1970-01-01.")
+public class GenericUDFToUnixTimeStamp extends GenericUDF {
+
+  private StringObjectInspector intputTextOI;
+  private TimestampObjectInspector inputTimestampOI;
+  private StringObjectInspector patternOI;
+
+  private String lasPattern = "yyyy-MM-dd HH:mm:ss";
+  private SimpleDateFormat formatter = new SimpleDateFormat(lasPattern);
+
+  @Override
+  public ObjectInspector initialize(ObjectInspector[] arguments) throws UDFArgumentException {
+    initializeInput(arguments);
+    return PrimitiveObjectInspectorFactory.writableLongObjectInspector;
+  }
+
+  protected void initializeInput(ObjectInspector[] arguments) throws UDFArgumentException {
+    if (arguments.length < 1) {
+      throw new UDFArgumentLengthException("The function TO_UNIX_TIMESTAMP " +
+          "requires at least one argument");
+    }
+
+    if (arguments[0] instanceof StringObjectInspector) {
+      intputTextOI = (StringObjectInspector) arguments[0];
+      if (arguments.length > 1) {
+        if (!(arguments[1] instanceof StringObjectInspector)) {
+          throw new UDFArgumentException(
+            "The time pattern for " + getName().toUpperCase() + " should be string type");
+        }
+        patternOI = (StringObjectInspector) arguments[1];
+      }
+    } else if (arguments[0] instanceof TimestampObjectInspector) {
+      inputTimestampOI = (TimestampObjectInspector) arguments[0];
+    } else {
+      throw new UDFArgumentException(
+          "The function " + getName().toUpperCase() + " takes only string or timestamp types");
+    }
+  }
+
+  protected String getName() {
+    return "to_unix_timestamp";
+  }
+
+  protected transient final LongWritable retValue = new LongWritable();
+
+  @Override
+  public Object evaluate(DeferredObject[] arguments) throws HiveException {
+    if (intputTextOI != null) {
+      String textVal = intputTextOI.getPrimitiveJavaObject(arguments[0].get());
+      if (textVal == null) {
+        return null;
+      }
+      if (patternOI != null) {
+        String patternVal = patternOI.getPrimitiveJavaObject(arguments[1].get());
+        if (patternVal == null) {
+          return null;
+        }
+        if (!patternVal.equals(lasPattern)) {
+          formatter.applyPattern(patternVal);
+          lasPattern = patternVal;
+        }
+      }
+      try {
+        retValue.set(formatter.parse(textVal).getTime() / 1000);
+        return retValue;
+      } catch (ParseException e) {
+        return null;
+      }
+    }
+    Timestamp timestamp = inputTimestampOI.getPrimitiveJavaObject(arguments[0].get());
+    retValue.set(timestamp.getTime() / 1000);
+    return retValue;
+  }
+
+  @Override
+  public String getDisplayString(String[] children) {
+    StringBuilder sb = new StringBuilder(32);
+    sb.append(getName());
+    sb.append('(');
+    sb.append(StringUtils.join(children, ','));
+    sb.append(')');
+    return sb.toString();
+  }
+}
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUnixTimeStamp.java b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUnixTimeStamp.java
new file mode 100644
index 0000000..1d64903
--- /dev/null
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUnixTimeStamp.java
@@ -0,0 +1,36 @@
+package org.apache.hadoop.hive.ql.udf.generic;
+
+import org.apache.hadoop.hive.ql.exec.Description;
+import org.apache.hadoop.hive.ql.exec.UDFArgumentException;
+import org.apache.hadoop.hive.ql.metadata.HiveException;
+import org.apache.hadoop.hive.ql.udf.UDFType;
+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;
+
+@UDFType(deterministic = false)
+@Description(name = "unix_timestamp",
+    value = "_FUNC_([date[, pattern]]) - Returns the UNIX timestamp",
+    extended = "Converts the current or specified time to number of seconds "
+        + "since 1970-01-01.")
+public class GenericUDFUnixTimeStamp extends GenericUDFToUnixTimeStamp {
+
+  @Override
+  protected void initializeInput(ObjectInspector[] arguments) throws UDFArgumentException {
+    if (arguments.length > 0) {
+      super.initializeInput(arguments);
+    }
+  }
+
+  @Override
+  protected String getName() {
+    return "unix_timestamp";
+  }
+
+  @Override
+  public Object evaluate(DeferredObject[] arguments) throws HiveException {
+    if (arguments.length == 0) {
+      retValue.set(System.currentTimeMillis() / 1000);
+      return retValue;
+    }
+    return super.evaluate(arguments);
+  }
+}
diff --git a/src/ql/src/test/queries/clientpositive/udf_to_unix_timestamp.q b/src/ql/src/test/queries/clientpositive/udf_to_unix_timestamp.q
new file mode 100644
index 0000000..3024074
--- /dev/null
+++ b/src/ql/src/test/queries/clientpositive/udf_to_unix_timestamp.q
@@ -0,0 +1,29 @@
+DESCRIBE FUNCTION to_unix_timestamp;
+DESCRIBE FUNCTION EXTENDED to_unix_timestamp;
+
+create table oneline(key int, value string);
+load data local inpath '../data/files/things.txt' into table oneline;
+
+SELECT
+  '2009-03-20 11:30:01',
+  to_unix_timestamp('2009-03-20 11:30:01')
+FROM oneline;
+
+SELECT
+  '2009-03-20',
+  to_unix_timestamp('2009-03-20', 'yyyy-MM-dd')
+FROM oneline;
+
+SELECT
+  '2009 Mar 20 11:30:01 am',
+  to_unix_timestamp('2009 Mar 20 11:30:01 am', 'yyyy MMM dd h:mm:ss a')
+FROM oneline;
+
+SELECT
+  'random_string',
+  to_unix_timestamp('random_string')
+FROM oneline;
+
+-- PPD
+explain select * from (select * from src) a where unix_timestamp(a.key) > 10;
+explain select * from (select * from src) a where to_unix_timestamp(a.key) > 10;
diff --git a/src/ql/src/test/queries/clientpositive/udf_unix_timestamp.q b/src/ql/src/test/queries/clientpositive/udf_unix_timestamp.q
index 9c38f53..89288a1 100644
--- a/src/ql/src/test/queries/clientpositive/udf_unix_timestamp.q
+++ b/src/ql/src/test/queries/clientpositive/udf_unix_timestamp.q
@@ -1,24 +1,27 @@
 DESCRIBE FUNCTION unix_timestamp;
 DESCRIBE FUNCTION EXTENDED unix_timestamp;
 
+create table oneline(key int, value string);
+load data local inpath '../data/files/things.txt' into table oneline;
+
 SELECT
   '2009-03-20 11:30:01',
   unix_timestamp('2009-03-20 11:30:01')
-FROM src LIMIT 1;
+FROM oneline;
 
 SELECT
   '2009-03-20',
   unix_timestamp('2009-03-20', 'yyyy-MM-dd')
-FROM src LIMIT 1;
+FROM oneline;
 
 SELECT
   '2009 Mar 20 11:30:01 am',
   unix_timestamp('2009 Mar 20 11:30:01 am', 'yyyy MMM dd h:mm:ss a')
-FROM src LIMIT 1;
+FROM oneline;
 
 SELECT
   'random_string',
   unix_timestamp('random_string')
-FROM src LIMIT 1;
+FROM oneline;
 
 
diff --git a/src/ql/src/test/results/clientpositive/show_functions.q.out b/src/ql/src/test/results/clientpositive/show_functions.q.out
index 7f45981..c4a885d 100644
--- a/src/ql/src/test/results/clientpositive/show_functions.q.out
+++ b/src/ql/src/test/results/clientpositive/show_functions.q.out
@@ -149,6 +149,7 @@ substring
 sum
 tan
 to_date
+to_unix_timestamp
 to_utc_timestamp
 translate
 trim
diff --git a/src/ql/src/test/results/clientpositive/udf5.q.out b/src/ql/src/test/results/clientpositive/udf5.q.out
index d21c498..a3b42f0 100644
--- a/src/ql/src/test/results/clientpositive/udf5.q.out
+++ b/src/ql/src/test/results/clientpositive/udf5.q.out
@@ -97,7 +97,7 @@ STAGE PLANS:
             alias: dest1
             Select Operator
               expressions:
-                    expr: from_unixtime(unix_timestamp('2010-01-13 11:57:40', 'yyyy-MM-dd HH:mm:ss'), 'MM/dd/yy HH:mm:ss')
+                    expr: from_unixtime(unix_timestamp('2010-01-13 11:57:40','yyyy-MM-dd HH:mm:ss'), 'MM/dd/yy HH:mm:ss')
                     type: string
                     expr: from_unixtime(unix_timestamp('2010-01-13 11:57:40'))
                     type: string
diff --git a/src/ql/src/test/results/clientpositive/udf_to_unix_timestamp.q.out b/src/ql/src/test/results/clientpositive/udf_to_unix_timestamp.q.out
new file mode 100644
index 0000000..0612dd7
--- /dev/null
+++ b/src/ql/src/test/results/clientpositive/udf_to_unix_timestamp.q.out
@@ -0,0 +1,180 @@
+PREHOOK: query: DESCRIBE FUNCTION to_unix_timestamp
+PREHOOK: type: DESCFUNCTION
+POSTHOOK: query: DESCRIBE FUNCTION to_unix_timestamp
+POSTHOOK: type: DESCFUNCTION
+to_unix_timestamp(date[, pattern]) - Returns the UNIX timestamp
+PREHOOK: query: DESCRIBE FUNCTION EXTENDED to_unix_timestamp
+PREHOOK: type: DESCFUNCTION
+POSTHOOK: query: DESCRIBE FUNCTION EXTENDED to_unix_timestamp
+POSTHOOK: type: DESCFUNCTION
+to_unix_timestamp(date[, pattern]) - Returns the UNIX timestamp
+Converts the specified time to number of seconds since 1970-01-01.
+PREHOOK: query: create table oneline(key int, value string)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table oneline(key int, value string)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@oneline
+PREHOOK: query: load data local inpath '../data/files/things.txt' into table oneline
+PREHOOK: type: LOAD
+PREHOOK: Output: default@oneline
+POSTHOOK: query: load data local inpath '../data/files/things.txt' into table oneline
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@oneline
+PREHOOK: query: SELECT
+  '2009-03-20 11:30:01',
+  to_unix_timestamp('2009-03-20 11:30:01')
+FROM oneline
+PREHOOK: type: QUERY
+PREHOOK: Input: default@oneline
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT
+  '2009-03-20 11:30:01',
+  to_unix_timestamp('2009-03-20 11:30:01')
+FROM oneline
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@oneline
+#### A masked pattern was here ####
+2009-03-20 11:30:01	1237573801
+PREHOOK: query: SELECT
+  '2009-03-20',
+  to_unix_timestamp('2009-03-20', 'yyyy-MM-dd')
+FROM oneline
+PREHOOK: type: QUERY
+PREHOOK: Input: default@oneline
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT
+  '2009-03-20',
+  to_unix_timestamp('2009-03-20', 'yyyy-MM-dd')
+FROM oneline
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@oneline
+#### A masked pattern was here ####
+2009-03-20	1237532400
+PREHOOK: query: SELECT
+  '2009 Mar 20 11:30:01 am',
+  to_unix_timestamp('2009 Mar 20 11:30:01 am', 'yyyy MMM dd h:mm:ss a')
+FROM oneline
+PREHOOK: type: QUERY
+PREHOOK: Input: default@oneline
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT
+  '2009 Mar 20 11:30:01 am',
+  to_unix_timestamp('2009 Mar 20 11:30:01 am', 'yyyy MMM dd h:mm:ss a')
+FROM oneline
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@oneline
+#### A masked pattern was here ####
+2009 Mar 20 11:30:01 am	1237573801
+PREHOOK: query: SELECT
+  'random_string',
+  to_unix_timestamp('random_string')
+FROM oneline
+PREHOOK: type: QUERY
+PREHOOK: Input: default@oneline
+#### A masked pattern was here ####
+POSTHOOK: query: SELECT
+  'random_string',
+  to_unix_timestamp('random_string')
+FROM oneline
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@oneline
+#### A masked pattern was here ####
+random_string	NULL
+PREHOOK: query: -- PPD
+explain select * from (select * from src) a where unix_timestamp(a.key) > 10
+PREHOOK: type: QUERY
+POSTHOOK: query: -- PPD
+explain select * from (select * from src) a where unix_timestamp(a.key) > 10
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)))) a)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)) (TOK_WHERE (> (TOK_FUNCTION unix_timestamp (. (TOK_TABLE_OR_COL a) key)) 10))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        a:src 
+          TableScan
+            alias: src
+            Select Operator
+              expressions:
+                    expr: key
+                    type: string
+                    expr: value
+                    type: string
+              outputColumnNames: _col0, _col1
+              Filter Operator
+                predicate:
+                    expr: (unix_timestamp(_col0) > 10)
+                    type: boolean
+                Select Operator
+                  expressions:
+                        expr: _col0
+                        type: string
+                        expr: _col1
+                        type: string
+                  outputColumnNames: _col0, _col1
+                  File Output Operator
+                    compressed: false
+                    GlobalTableId: 0
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+
+
+PREHOOK: query: explain select * from (select * from src) a where to_unix_timestamp(a.key) > 10
+PREHOOK: type: QUERY
+POSTHOOK: query: explain select * from (select * from src) a where to_unix_timestamp(a.key) > 10
+POSTHOOK: type: QUERY
+ABSTRACT SYNTAX TREE:
+  (TOK_QUERY (TOK_FROM (TOK_SUBQUERY (TOK_QUERY (TOK_FROM (TOK_TABREF (TOK_TABNAME src))) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)))) a)) (TOK_INSERT (TOK_DESTINATION (TOK_DIR TOK_TMP_FILE)) (TOK_SELECT (TOK_SELEXPR TOK_ALLCOLREF)) (TOK_WHERE (> (TOK_FUNCTION to_unix_timestamp (. (TOK_TABLE_OR_COL a) key)) 10))))
+
+STAGE DEPENDENCIES:
+  Stage-1 is a root stage
+  Stage-0 is a root stage
+
+STAGE PLANS:
+  Stage: Stage-1
+    Map Reduce
+      Alias -> Map Operator Tree:
+        a:src 
+          TableScan
+            alias: src
+            Filter Operator
+              predicate:
+                  expr: (to_unix_timestamp(key) > 10)
+                  type: boolean
+              Select Operator
+                expressions:
+                      expr: key
+                      type: string
+                      expr: value
+                      type: string
+                outputColumnNames: _col0, _col1
+                Select Operator
+                  expressions:
+                        expr: _col0
+                        type: string
+                        expr: _col1
+                        type: string
+                  outputColumnNames: _col0, _col1
+                  File Output Operator
+                    compressed: false
+                    GlobalTableId: 0
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+
+  Stage: Stage-0
+    Fetch Operator
+      limit: -1
+
+
diff --git a/src/ql/src/test/results/clientpositive/udf_unix_timestamp.q.out b/src/ql/src/test/results/clientpositive/udf_unix_timestamp.q.out
index 251a119..cb47182 100644
--- a/src/ql/src/test/results/clientpositive/udf_unix_timestamp.q.out
+++ b/src/ql/src/test/results/clientpositive/udf_unix_timestamp.q.out
@@ -9,63 +9,74 @@ POSTHOOK: query: DESCRIBE FUNCTION EXTENDED unix_timestamp
 POSTHOOK: type: DESCFUNCTION
 unix_timestamp([date[, pattern]]) - Returns the UNIX timestamp
 Converts the current or specified time to number of seconds since 1970-01-01.
+PREHOOK: query: create table oneline(key int, value string)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table oneline(key int, value string)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@oneline
+PREHOOK: query: load data local inpath '../data/files/things.txt' into table oneline
+PREHOOK: type: LOAD
+PREHOOK: Output: default@oneline
+POSTHOOK: query: load data local inpath '../data/files/things.txt' into table oneline
+POSTHOOK: type: LOAD
+POSTHOOK: Output: default@oneline
 PREHOOK: query: SELECT
   '2009-03-20 11:30:01',
   unix_timestamp('2009-03-20 11:30:01')
-FROM src LIMIT 1
+FROM oneline
 PREHOOK: type: QUERY
-PREHOOK: Input: default@src
+PREHOOK: Input: default@oneline
 #### A masked pattern was here ####
 POSTHOOK: query: SELECT
   '2009-03-20 11:30:01',
   unix_timestamp('2009-03-20 11:30:01')
-FROM src LIMIT 1
+FROM oneline
 POSTHOOK: type: QUERY
-POSTHOOK: Input: default@src
+POSTHOOK: Input: default@oneline
 #### A masked pattern was here ####
 2009-03-20 11:30:01	1237573801
 PREHOOK: query: SELECT
   '2009-03-20',
   unix_timestamp('2009-03-20', 'yyyy-MM-dd')
-FROM src LIMIT 1
+FROM oneline
 PREHOOK: type: QUERY
-PREHOOK: Input: default@src
+PREHOOK: Input: default@oneline
 #### A masked pattern was here ####
 POSTHOOK: query: SELECT
   '2009-03-20',
   unix_timestamp('2009-03-20', 'yyyy-MM-dd')
-FROM src LIMIT 1
+FROM oneline
 POSTHOOK: type: QUERY
-POSTHOOK: Input: default@src
+POSTHOOK: Input: default@oneline
 #### A masked pattern was here ####
 2009-03-20	1237532400
 PREHOOK: query: SELECT
   '2009 Mar 20 11:30:01 am',
   unix_timestamp('2009 Mar 20 11:30:01 am', 'yyyy MMM dd h:mm:ss a')
-FROM src LIMIT 1
+FROM oneline
 PREHOOK: type: QUERY
-PREHOOK: Input: default@src
+PREHOOK: Input: default@oneline
 #### A masked pattern was here ####
 POSTHOOK: query: SELECT
   '2009 Mar 20 11:30:01 am',
   unix_timestamp('2009 Mar 20 11:30:01 am', 'yyyy MMM dd h:mm:ss a')
-FROM src LIMIT 1
+FROM oneline
 POSTHOOK: type: QUERY
-POSTHOOK: Input: default@src
+POSTHOOK: Input: default@oneline
 #### A masked pattern was here ####
 2009 Mar 20 11:30:01 am	1237573801
 PREHOOK: query: SELECT
   'random_string',
   unix_timestamp('random_string')
-FROM src LIMIT 1
+FROM oneline
 PREHOOK: type: QUERY
-PREHOOK: Input: default@src
+PREHOOK: Input: default@oneline
 #### A masked pattern was here ####
 POSTHOOK: query: SELECT
   'random_string',
   unix_timestamp('random_string')
-FROM src LIMIT 1
+FROM oneline
 POSTHOOK: type: QUERY
-POSTHOOK: Input: default@src
+POSTHOOK: Input: default@oneline
 #### A masked pattern was here ####
 random_string	NULL
-- 
1.7.0.4

