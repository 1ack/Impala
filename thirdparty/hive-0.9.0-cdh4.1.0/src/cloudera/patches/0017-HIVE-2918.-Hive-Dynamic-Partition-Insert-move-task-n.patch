From dca45a0174770c82258f7235858f94a90961b068 Mon Sep 17 00:00:00 2001
From: Kevin Wilfong <kevinwilfong@apache.org>
Date: Wed, 25 Apr 2012 16:58:54 +0000
Subject: [PATCH 017/144] HIVE-2918. Hive Dynamic Partition Insert - move task not considering 'hive.exec.max.dynamic.partitions' from CLI. (cwsteinbach via kevinwilfong)

git-svn-id: https://svn.apache.org/repos/asf/hive/trunk@1330417 13f79535-47bb-0310-9956-ffa450edef68
---
 .../org/apache/hadoop/hive/ql/metadata/Hive.java   |    1 +
 ql/src/test/queries/clientnegative/dyn_part_max.q  |   16 ++++++++++
 .../queries/clientnegative/dyn_part_max_per_node.q |   15 +++++++++
 .../test/results/clientnegative/dyn_part_max.q.out |   24 +++++++++++++++
 .../clientnegative/dyn_part_max_per_node.q.out     |   31 ++++++++++++++++++++
 5 files changed, 87 insertions(+), 0 deletions(-)
 create mode 100644 ql/src/test/queries/clientnegative/dyn_part_max.q
 create mode 100644 ql/src/test/queries/clientnegative/dyn_part_max_per_node.q
 create mode 100644 ql/src/test/results/clientnegative/dyn_part_max.q.out
 create mode 100644 ql/src/test/results/clientnegative/dyn_part_max_per_node.q.out

diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java b/src/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
index 0531620..55c6f38 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java
@@ -164,6 +164,7 @@ public class Hive {
       hiveDB.set(newdb);
       return newdb;
     }
+    db.conf = c;
     return db;
   }
 
diff --git a/src/ql/src/test/queries/clientnegative/dyn_part_max.q b/src/ql/src/test/queries/clientnegative/dyn_part_max.q
new file mode 100644
index 0000000..6a7a625
--- /dev/null
+++ b/src/ql/src/test/queries/clientnegative/dyn_part_max.q
@@ -0,0 +1,16 @@
+USE default;
+
+-- Test of hive.exec.max.dynamic.partitions
+-- Set hive.exec.max.dynamic.partitions.pernode to a large value so it will be ignored
+
+CREATE TABLE max_parts(key STRING) PARTITIONED BY (value STRING);
+
+set hive.exec.dynamic.partition=true;
+set hive.exec.dynamic.partition.mode=nonstrict;
+set hive.exec.max.dynamic.partitions=10;
+set hive.exec.max.dynamic.partitions.pernode=1000;
+
+INSERT OVERWRITE TABLE max_parts PARTITION(value)
+SELECT key, value
+FROM src
+LIMIT 50;
diff --git a/src/ql/src/test/queries/clientnegative/dyn_part_max_per_node.q b/src/ql/src/test/queries/clientnegative/dyn_part_max_per_node.q
new file mode 100644
index 0000000..a411ec5
--- /dev/null
+++ b/src/ql/src/test/queries/clientnegative/dyn_part_max_per_node.q
@@ -0,0 +1,15 @@
+USE default;
+
+-- Test of hive.exec.max.dynamic.partitions.pernode
+
+CREATE TABLE max_parts(key STRING) PARTITIONED BY (value STRING);
+
+set hive.exec.dynamic.partition=true;
+set hive.exec.dynamic.partition.mode=nonstrict;
+set hive.exec.max.dynamic.partitions=1000;
+set hive.exec.max.dynamic.partitions.pernode=10;
+
+INSERT OVERWRITE TABLE max_parts PARTITION(value)
+SELECT key, value
+FROM src
+LIMIT 50;
diff --git a/src/ql/src/test/results/clientnegative/dyn_part_max.q.out b/src/ql/src/test/results/clientnegative/dyn_part_max.q.out
new file mode 100644
index 0000000..eb91275
--- /dev/null
+++ b/src/ql/src/test/results/clientnegative/dyn_part_max.q.out
@@ -0,0 +1,24 @@
+PREHOOK: query: USE default
+PREHOOK: type: SWITCHDATABASE
+POSTHOOK: query: USE default
+POSTHOOK: type: SWITCHDATABASE
+PREHOOK: query: -- Test of hive.exec.max.dynamic.partitions
+-- Set hive.exec.max.dynamic.partitions.pernode to a large value so it will be ignored
+
+CREATE TABLE max_parts(key STRING) PARTITIONED BY (value STRING)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: -- Test of hive.exec.max.dynamic.partitions
+-- Set hive.exec.max.dynamic.partitions.pernode to a large value so it will be ignored
+
+CREATE TABLE max_parts(key STRING) PARTITIONED BY (value STRING)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@max_parts
+PREHOOK: query: INSERT OVERWRITE TABLE max_parts PARTITION(value)
+SELECT key, value
+FROM src
+LIMIT 50
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@max_parts
+Failed with exception Number of dynamic partitions created is 49, which is more than 10. To solve this try to set hive.exec.max.dynamic.partitions to at least 49.
+FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.MoveTask
diff --git a/src/ql/src/test/results/clientnegative/dyn_part_max_per_node.q.out b/src/ql/src/test/results/clientnegative/dyn_part_max_per_node.q.out
new file mode 100644
index 0000000..3a3bb1e
--- /dev/null
+++ b/src/ql/src/test/results/clientnegative/dyn_part_max_per_node.q.out
@@ -0,0 +1,31 @@
+PREHOOK: query: USE default
+PREHOOK: type: SWITCHDATABASE
+POSTHOOK: query: USE default
+POSTHOOK: type: SWITCHDATABASE
+PREHOOK: query: -- Test of hive.exec.max.dynamic.partitions.pernode
+
+CREATE TABLE max_parts(key STRING) PARTITIONED BY (value STRING)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: -- Test of hive.exec.max.dynamic.partitions.pernode
+
+CREATE TABLE max_parts(key STRING) PARTITIONED BY (value STRING)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@max_parts
+PREHOOK: query: INSERT OVERWRITE TABLE max_parts PARTITION(value)
+SELECT key, value
+FROM src
+LIMIT 50
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@max_parts
+Execution failed with exit status: 2
+Obtaining error information
+
+Task failed!
+Task ID:
+  Stage-1
+
+Logs:
+
+#### A masked pattern was here ####
+FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.MapRedTask
-- 
1.7.0.4

