From fa66dac9b2b735c82cb059cec03496951bb13db1 Mon Sep 17 00:00:00 2001
From: Kevin Wilfong <kevinwilfong@apache.org>
Date: Tue, 17 Apr 2012 17:23:04 +0000
Subject: [PATCH 008/148] HIVE-2530. Implement SHOW TBLPROPERTIES. (leizhao via kevinwilfong)

git-svn-id: https://svn.apache.org/repos/asf/hive/trunk@1327189 13f79535-47bb-0310-9956-ffa450edef68
---
 .../org/apache/hadoop/hive/ql/exec/DDLTask.java    |   75 ++++++++++++
 .../hadoop/hive/ql/parse/DDLSemanticAnalyzer.java  |   20 +++
 ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g |    2 +
 .../apache/hadoop/hive/ql/parse/ParseDriver.java   |    1 +
 .../hive/ql/parse/SemanticAnalyzerFactory.java     |    2 +
 .../org/apache/hadoop/hive/ql/plan/DDLWork.java    |   20 +++
 .../apache/hadoop/hive/ql/plan/HiveOperation.java  |    1 +
 .../hadoop/hive/ql/plan/ShowTblPropertiesDesc.java |  124 ++++++++++++++++++++
 .../queries/clientpositive/show_tblproperties.q    |   12 ++
 .../clientpositive/show_tblproperties.q.out        |   53 +++++++++
 10 files changed, 310 insertions(+), 0 deletions(-)
 create mode 100644 ql/src/java/org/apache/hadoop/hive/ql/plan/ShowTblPropertiesDesc.java
 create mode 100644 ql/src/test/queries/clientpositive/show_tblproperties.q
 create mode 100644 ql/src/test/results/clientpositive/show_tblproperties.q.out

diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java b/src/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
index bf7a1aa..aace1fa 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
@@ -136,6 +136,7 @@ import org.apache.hadoop.hive.ql.plan.ShowLocksDesc;
 import org.apache.hadoop.hive.ql.plan.ShowPartitionsDesc;
 import org.apache.hadoop.hive.ql.plan.ShowTableStatusDesc;
 import org.apache.hadoop.hive.ql.plan.ShowTablesDesc;
+import org.apache.hadoop.hive.ql.plan.ShowTblPropertiesDesc;
 import org.apache.hadoop.hive.ql.plan.SwitchDatabaseDesc;
 import org.apache.hadoop.hive.ql.plan.UnlockTableDesc;
 import org.apache.hadoop.hive.ql.plan.api.StageType;
@@ -328,6 +329,11 @@ public class DDLTask extends Task<DDLWork> implements Serializable {
         return showTableStatus(db, showTblStatus);
       }
 
+      ShowTblPropertiesDesc showTblProperties = work.getShowTblPropertiesDesc();
+      if (showTblProperties != null) {
+        return showTableProperties(db, showTblProperties);
+      }
+
       ShowFunctionsDesc showFuncs = work.getShowFuncsDesc();
       if (showFuncs != null) {
         return showFunctions(showFuncs);
@@ -2451,6 +2457,75 @@ public class DDLTask extends Task<DDLWork> implements Serializable {
   }
 
   /**
+   * Write the properties of a table to a file.
+   *
+   * @param db
+   *          The database in question.
+   * @param showTblPrpt
+   *          This is the table we're interested in.
+   * @return Returns 0 when execution succeeds and above 0 if it fails.
+   * @throws HiveException
+   *           Throws this exception if an unexpected error occurs.
+   */
+  private int showTableProperties(Hive db, ShowTblPropertiesDesc showTblPrpt) throws HiveException {
+    String tableName = showTblPrpt.getTableName();
+
+    // show table properties - populate the output stream
+    Table tbl = db.getTable(tableName, false);
+    DataOutput outStream = null;
+    try {
+      Path resFile = new Path(showTblPrpt.getResFile());
+      FileSystem fs = resFile.getFileSystem(conf);
+      outStream = fs.create(resFile);
+
+      if (tbl == null) {
+        String errMsg = "Table " + tableName + " does not exist";
+        outStream.write(errMsg.getBytes("UTF-8"));
+        ((FSDataOutputStream) outStream).close();
+        outStream = null;
+        return 0;
+      }
+
+      LOG.info("DDLTask: show properties for " + tbl.getTableName());
+
+      String propertyName = showTblPrpt.getPropertyName();
+      if (propertyName != null) {
+        String propertyValue = tbl.getProperty(propertyName);
+        if (propertyValue == null) {
+          String errMsg = "Table " + tableName + " does not have property: " + propertyName;
+          outStream.write(errMsg.getBytes("UTF-8"));
+        }
+        else {
+          outStream.writeBytes(propertyValue);
+        }
+      }
+      else {
+        Map<String, String> properties = tbl.getParameters();
+        for (String key : properties.keySet()) {
+          writeKeyValuePair(outStream, key, properties.get(key));
+        }
+      }
+
+      LOG.info("DDLTask: written data for showing properties of " + tbl.getTableName());
+      ((FSDataOutputStream) outStream).close();
+      outStream = null;
+
+    } catch (FileNotFoundException e) {
+      LOG.info("show table properties: " + stringifyException(e));
+      return 1;
+    } catch (IOException e) {
+      LOG.info("show table properties: " + stringifyException(e));
+      return 1;
+    } catch (Exception e) {
+      throw new HiveException(e);
+    } finally {
+      IOUtils.closeStream((FSDataOutputStream) outStream);
+    }
+
+    return 0;
+  }
+
+  /**
    * Write the description of a table to a file.
    *
    * @param db
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java
index f563f88..afa754b 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java
@@ -105,6 +105,7 @@ import org.apache.hadoop.hive.ql.plan.ShowLocksDesc;
 import org.apache.hadoop.hive.ql.plan.ShowPartitionsDesc;
 import org.apache.hadoop.hive.ql.plan.ShowTableStatusDesc;
 import org.apache.hadoop.hive.ql.plan.ShowTablesDesc;
+import org.apache.hadoop.hive.ql.plan.ShowTblPropertiesDesc;
 import org.apache.hadoop.hive.ql.plan.StatsWork;
 import org.apache.hadoop.hive.ql.plan.SwitchDatabaseDesc;
 import org.apache.hadoop.hive.ql.plan.TableDesc;
@@ -231,6 +232,10 @@ public class DDLSemanticAnalyzer extends BaseSemanticAnalyzer {
       ctx.setResFile(new Path(ctx.getLocalTmpFileURI()));
       analyzeShowTableStatus(ast);
       break;
+    case HiveParser.TOK_SHOW_TBLPROPERTIES:
+      ctx.setResFile(new Path(ctx.getLocalTmpFileURI()));
+      analyzeShowTableProperties(ast);
+      break;
     case HiveParser.TOK_SHOWFUNCTIONS:
       ctx.setResFile(new Path(ctx.getLocalTmpFileURI()));
       analyzeShowFunctions(ast);
@@ -1482,6 +1487,21 @@ public class DDLSemanticAnalyzer extends BaseSemanticAnalyzer {
     setFetchTask(createFetchTask(showTblStatusDesc.getSchema()));
   }
 
+  private void analyzeShowTableProperties(ASTNode ast) throws SemanticException {
+    ShowTblPropertiesDesc showTblPropertiesDesc;
+    String tableNames = getUnescapedName((ASTNode)ast.getChild(0));
+    String dbName = db.getCurrentDatabase();
+    String propertyName = null;
+    if (ast.getChildCount() > 1) {
+      propertyName = unescapeSQLString(ast.getChild(1).getText());
+    }
+    showTblPropertiesDesc = new ShowTblPropertiesDesc(ctx.getResFile().toString(), tableNames,
+        propertyName);
+    rootTasks.add(TaskFactory.get(new DDLWork(getInputs(), getOutputs(),
+        showTblPropertiesDesc), conf));
+    setFetchTask(createFetchTask(showTblPropertiesDesc.getSchema()));
+  }
+
   private void analyzeShowIndexes(ASTNode ast) throws SemanticException {
     ShowIndexesDesc showIndexesDesc;
     String tableName = getUnescapedName((ASTNode)ast.getChild(0));
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g
index f22cc2e..1e7ef40 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/Hive.g
@@ -144,6 +144,7 @@ TOK_SHOWTABLES;
 TOK_SHOWFUNCTIONS;
 TOK_SHOWPARTITIONS;
 TOK_SHOW_TABLESTATUS;
+TOK_SHOW_TBLPROPERTIES;
 TOK_SHOWLOCKS;
 TOK_LOCKTABLE;
 TOK_UNLOCKTABLE;
@@ -846,6 +847,7 @@ showStatement
     | KW_SHOW KW_PARTITIONS Identifier partitionSpec? -> ^(TOK_SHOWPARTITIONS Identifier partitionSpec?)
     | KW_SHOW KW_TABLE KW_EXTENDED ((KW_FROM|KW_IN) db_name=Identifier)? KW_LIKE showStmtIdentifier partitionSpec?
     -> ^(TOK_SHOW_TABLESTATUS showStmtIdentifier $db_name? partitionSpec?)
+    | KW_SHOW KW_TBLPROPERTIES tblName=Identifier (LPAREN prptyName=StringLiteral RPAREN)? -> ^(TOK_SHOW_TBLPROPERTIES $tblName $prptyName?)
     | KW_SHOW KW_LOCKS (parttype=partTypeExpr)? (isExtended=KW_EXTENDED)? -> ^(TOK_SHOWLOCKS $parttype? $isExtended?)
     | KW_SHOW (showOptions=KW_FORMATTED)? (KW_INDEX|KW_INDEXES) KW_ON showStmtIdentifier ((KW_FROM|KW_IN) db_name=Identifier)?
     -> ^(TOK_SHOWINDEXES showStmtIdentifier $showOptions? $db_name?)
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/ParseDriver.java b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/ParseDriver.java
index 4c4beee..440b0a4 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/ParseDriver.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/ParseDriver.java
@@ -82,6 +82,7 @@ public class ParseDriver {
     xlateMap.put("KW_PARTITIONS", "PARTITIONS");
     xlateMap.put("KW_TABLE", "TABLE");
     xlateMap.put("KW_TABLES", "TABLES");
+    xlateMap.put("KW_TBLPROPERTIES", "TBLPROPERTIES");
     xlateMap.put("KW_SHOW", "SHOW");
     xlateMap.put("KW_MSCK", "MSCK");
     xlateMap.put("KW_DIRECTORY", "DIRECTORY");
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java
index 510c43d..330bed3 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java
@@ -60,6 +60,7 @@ public final class SemanticAnalyzerFactory {
     commandType.put(HiveParser.TOK_SHOWDATABASES, HiveOperation.SHOWDATABASES);
     commandType.put(HiveParser.TOK_SHOWTABLES, HiveOperation.SHOWTABLES);
     commandType.put(HiveParser.TOK_SHOW_TABLESTATUS, HiveOperation.SHOW_TABLESTATUS);
+    commandType.put(HiveParser.TOK_SHOW_TBLPROPERTIES, HiveOperation.SHOW_TBLPROPERTIES);
     commandType.put(HiveParser.TOK_SHOWFUNCTIONS, HiveOperation.SHOWFUNCTIONS);
     commandType.put(HiveParser.TOK_SHOWINDEXES, HiveOperation.SHOWINDEXES);
     commandType.put(HiveParser.TOK_SHOWPARTITIONS, HiveOperation.SHOWPARTITIONS);
@@ -157,6 +158,7 @@ public final class SemanticAnalyzerFactory {
       case HiveParser.TOK_SHOWDATABASES:
       case HiveParser.TOK_SHOWTABLES:
       case HiveParser.TOK_SHOW_TABLESTATUS:
+      case HiveParser.TOK_SHOW_TBLPROPERTIES:
       case HiveParser.TOK_SHOWFUNCTIONS:
       case HiveParser.TOK_SHOWPARTITIONS:
       case HiveParser.TOK_SHOWINDEXES:
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/plan/DDLWork.java b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/DDLWork.java
index b865f04..32010a1 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/plan/DDLWork.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/DDLWork.java
@@ -45,6 +45,7 @@ public class DDLWork implements Serializable {
   private AlterIndexDesc alterIdxDesc;
   private ShowDatabasesDesc showDatabasesDesc;
   private ShowTablesDesc showTblsDesc;
+  private ShowTblPropertiesDesc showTblPropertiesDesc;
   private LockTableDesc lockTblDesc;
   private UnlockTableDesc unlockTblDesc;
   private ShowFunctionsDesc showFuncsDesc;
@@ -354,6 +355,17 @@ public class DDLWork implements Serializable {
     this.showTblStatusDesc = showTblStatusDesc;
   }
 
+  /**
+   * @param showTblPropertiesDesc
+   *          show table properties descriptor
+   */
+  public DDLWork(HashSet<ReadEntity> inputs, HashSet<WriteEntity> outputs,
+      ShowTblPropertiesDesc showTblPropertiesDesc) {
+    this(inputs, outputs);
+
+    this.showTblPropertiesDesc = showTblPropertiesDesc;
+  }
+
   public DDLWork(HashSet<ReadEntity> inputs, HashSet<WriteEntity> outputs,
       DropIndexDesc dropIndexDesc) {
     this(inputs, outputs);
@@ -788,6 +800,14 @@ public class DDLWork implements Serializable {
     this.showTblStatusDesc = showTblStatusDesc;
   }
 
+  public ShowTblPropertiesDesc getShowTblPropertiesDesc() {
+    return showTblPropertiesDesc;
+  }
+
+  public void setShowTblPropertiesDesc(ShowTblPropertiesDesc showTblPropertiesDesc) {
+    this.showTblPropertiesDesc = showTblPropertiesDesc;
+  }
+
   public CreateViewDesc getCreateVwDesc() {
     return createVwDesc;
   }
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/plan/HiveOperation.java b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/HiveOperation.java
index 053e184..0305776 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/plan/HiveOperation.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/HiveOperation.java
@@ -52,6 +52,7 @@ public enum HiveOperation {
   SHOWDATABASES("SHOWDATABASES", new Privilege[]{Privilege.SHOW_DATABASE}, null),
   SHOWTABLES("SHOWTABLES", null, null),
   SHOW_TABLESTATUS("SHOW_TABLESTATUS", null, null),
+  SHOW_TBLPROPERTIES("SHOW_TBLPROPERTIES", null, null),
   SHOWFUNCTIONS("SHOWFUNCTIONS", null, null),
   SHOWINDEXES("SHOWINDEXES", null, null),
   SHOWPARTITIONS("SHOWPARTITIONS", null, null),
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ShowTblPropertiesDesc.java b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ShowTblPropertiesDesc.java
new file mode 100644
index 0000000..13de46e
--- /dev/null
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/ShowTblPropertiesDesc.java
@@ -0,0 +1,124 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.hive.ql.plan;
+
+import java.io.Serializable;
+import java.util.HashMap;
+
+import org.apache.hadoop.fs.Path;
+
+/**
+ * ShowTblPropertiesDesc.
+ *
+ */
+@Explain(displayName = "Show Table Properties")
+public class ShowTblPropertiesDesc extends DDLDesc implements Serializable {
+  private static final long serialVersionUID = 1L;
+  String resFile;
+  String tableName;
+  String propertyName;
+
+  /**
+   * table name for the result of showtblproperties.
+   */
+  private static final String table = "show_tableproperties";
+  /**
+   * thrift ddl for the result of showtblproperties.
+   */
+  private static final String schema = "prpt_name,prpt_value#string:string";
+
+  public String getTable() {
+    return table;
+  }
+
+  public String getSchema() {
+    return schema;
+  }
+
+  /**
+   * For serialization use only.
+   */
+  public ShowTblPropertiesDesc() {
+  }
+
+  /**
+   * @param resFile
+   * @param tableName
+   *          name of table to show
+   * @param propertyName
+   *          name of property to show
+   */
+  public ShowTblPropertiesDesc(String resFile, String tableName, String propertyName) {
+    this.resFile = resFile;
+    this.tableName = tableName;
+    this.propertyName = propertyName;
+  }
+
+  /**
+   * @return the resFile
+   */
+  public String getResFile() {
+    return resFile;
+  }
+
+  @Explain(displayName = "result file", normalExplain = false)
+  public String getResFileString() {
+    return getResFile();
+  }
+
+  /**
+   * @param resFile
+   *          the resFile to set
+   */
+  public void setResFile(String resFile) {
+    this.resFile = resFile;
+  }
+
+  /**
+   * @return the tableName
+   */
+  @Explain(displayName = "table name")
+  public String getTableName() {
+    return tableName;
+  }
+
+  /**
+   * @param tableName
+   *          the tableName to set
+   */
+  public void setTableName(String tableName) {
+    this.tableName = tableName;
+  }
+
+  /**
+   * @return the propertyName
+   */
+  @Explain(displayName = "property name")
+  public String getPropertyName() {
+    return propertyName;
+  }
+
+  /**
+   * @param propertyName
+   *          the propertyName to set
+   */
+  public void setPropertyName(String propertyName) {
+    this.propertyName = propertyName;
+  }
+}
diff --git a/src/ql/src/test/queries/clientpositive/show_tblproperties.q b/src/ql/src/test/queries/clientpositive/show_tblproperties.q
new file mode 100644
index 0000000..1d58f27
--- /dev/null
+++ b/src/ql/src/test/queries/clientpositive/show_tblproperties.q
@@ -0,0 +1,12 @@
+show tblproperties tmpfoo;
+
+create table tmpfoo (a String);
+show tblproperties tmpfoo("bar");
+
+alter table tmpfoo set tblproperties ("bar" = "bar value");
+alter table tmpfoo set tblproperties ("tmp" = "true");
+
+show tblproperties tmpfoo;
+show tblproperties tmpfoo("bar");
+
+drop table tmpfoo;
diff --git a/src/ql/src/test/results/clientpositive/show_tblproperties.q.out b/src/ql/src/test/results/clientpositive/show_tblproperties.q.out
new file mode 100644
index 0000000..7ae2cba
--- /dev/null
+++ b/src/ql/src/test/results/clientpositive/show_tblproperties.q.out
@@ -0,0 +1,53 @@
+PREHOOK: query: show tblproperties tmpfoo
+PREHOOK: type: SHOW_TBLPROPERTIES
+POSTHOOK: query: show tblproperties tmpfoo
+POSTHOOK: type: SHOW_TBLPROPERTIES
+Table tmpfoo does not exist	 
+PREHOOK: query: create table tmpfoo (a String)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table tmpfoo (a String)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@tmpfoo
+PREHOOK: query: show tblproperties tmpfoo("bar")
+PREHOOK: type: SHOW_TBLPROPERTIES
+POSTHOOK: query: show tblproperties tmpfoo("bar")
+POSTHOOK: type: SHOW_TBLPROPERTIES
+Table tmpfoo does not have property: bar	 
+PREHOOK: query: alter table tmpfoo set tblproperties ("bar" = "bar value")
+PREHOOK: type: ALTERTABLE_PROPERTIES
+PREHOOK: Input: default@tmpfoo
+PREHOOK: Output: default@tmpfoo
+POSTHOOK: query: alter table tmpfoo set tblproperties ("bar" = "bar value")
+POSTHOOK: type: ALTERTABLE_PROPERTIES
+POSTHOOK: Input: default@tmpfoo
+POSTHOOK: Output: default@tmpfoo
+PREHOOK: query: alter table tmpfoo set tblproperties ("tmp" = "true")
+PREHOOK: type: ALTERTABLE_PROPERTIES
+PREHOOK: Input: default@tmpfoo
+PREHOOK: Output: default@tmpfoo
+POSTHOOK: query: alter table tmpfoo set tblproperties ("tmp" = "true")
+POSTHOOK: type: ALTERTABLE_PROPERTIES
+POSTHOOK: Input: default@tmpfoo
+POSTHOOK: Output: default@tmpfoo
+PREHOOK: query: show tblproperties tmpfoo
+PREHOOK: type: SHOW_TBLPROPERTIES
+POSTHOOK: query: show tblproperties tmpfoo
+POSTHOOK: type: SHOW_TBLPROPERTIES
+	 
+#### A masked pattern was here ####
+tmp	true
+#### A masked pattern was here ####
+bar	bar value
+PREHOOK: query: show tblproperties tmpfoo("bar")
+PREHOOK: type: SHOW_TBLPROPERTIES
+POSTHOOK: query: show tblproperties tmpfoo("bar")
+POSTHOOK: type: SHOW_TBLPROPERTIES
+bar value	 
+PREHOOK: query: drop table tmpfoo
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: default@tmpfoo
+PREHOOK: Output: default@tmpfoo
+POSTHOOK: query: drop table tmpfoo
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: default@tmpfoo
+POSTHOOK: Output: default@tmpfoo
-- 
1.7.0.4

