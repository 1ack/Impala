From af701fa34e93affdc80da2e825fa280a236073ed Mon Sep 17 00:00:00 2001
From: Namit Jain <namit@apache.org>
Date: Mon, 11 Jun 2012 11:54:02 +0000
Subject: [PATCH 082/148] HIVE-3061 hive.binary.record.max.length is a magic string
 (Edward Capriolo via namit)

git-svn-id: https://svn.apache.org/repos/asf/hive/trunk@1348808 13f79535-47bb-0310-9956-ffa450edef68
(cherry picked from commit 00f6d0ace79debc44a672ab765de92b7afcbfebd)
---
 .../java/org/apache/hadoop/hive/conf/HiveConf.java |    1 +
 conf/hive-default.xml.template                     |    8 ++++++++
 .../hadoop/hive/ql/exec/BinaryRecordReader.java    |    9 +++++----
 3 files changed, 14 insertions(+), 4 deletions(-)

diff --git a/src/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java b/src/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
index d446028..75e14ed 100644
--- a/src/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
+++ b/src/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java
@@ -391,6 +391,7 @@ public class HiveConf extends Configuration {
     HIVESCRIPTRECORDWRITER("hive.script.recordwriter",
         "org.apache.hadoop.hive.ql.exec.TextRecordWriter"),
     HIVESCRIPTESCAPE("hive.transform.escape.input", false),
+    HIVEBINARYRECORDMAX("hive.binary.record.max.length", 1000 ),
 
     // HWI
     HIVEHWILISTENHOST("hive.hwi.listen.host", "0.0.0.0"),
diff --git a/src/conf/hive-default.xml.template b/src/conf/hive-default.xml.template
index b5d14bf..3965329 100644
--- a/src/conf/hive-default.xml.template
+++ b/src/conf/hive-default.xml.template
@@ -664,6 +664,14 @@
 </property>
 
 <property>
+  <name>hive.binary.record.max.length</name>
+  <value>1000</value>
+  <description>Read from a binary stream and treat each hive.binary.record.max.length bytes as a record.
+  The last record before the end of stream can have less than hive.binary.record.max.length bytes</description>
+</property>
+
+
+<property>
   <name>hive.script.recordreader</name>
   <value>org.apache.hadoop.hive.ql.exec.TextRecordReader</value>
   <description>The default record reader for reading data from the user scripts. </description>
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/exec/BinaryRecordReader.java b/src/ql/src/java/org/apache/hadoop/hive/ql/exec/BinaryRecordReader.java
index 7f7cca1..186bcbe 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/exec/BinaryRecordReader.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/exec/BinaryRecordReader.java
@@ -25,11 +25,12 @@ import java.util.Properties;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.io.BytesWritable;
 import org.apache.hadoop.io.Writable;
+import org.apache.hadoop.hive.conf.HiveConf;
 
 /**
- * Read from a binary stream and treat each 1000 bytes (configurable via 
- * hive.binary.record.max.length) as a record.  The last record before the 
- * end of stream can have less than 1000 bytes. 
+ * Read from a binary stream and treat each 1000 bytes (configurable via
+ * hive.binary.record.max.length) as a record.  The last record before the
+ * end of stream can have less than 1000 bytes.
  */
 public class BinaryRecordReader implements RecordReader {
 
@@ -39,7 +40,7 @@ public class BinaryRecordReader implements RecordReader {
 
   public void initialize(InputStream in, Configuration conf, Properties tbl) throws IOException {
     this.in = in;
-    maxRecordLength = conf.getInt("hive.binary.record.max.length", 1000);
+    maxRecordLength = HiveConf.getIntVar(conf, HiveConf.ConfVars.HIVEBINARYRECORDMAX);
   }
 
   public Writable createRow() throws IOException {
-- 
1.7.0.4

