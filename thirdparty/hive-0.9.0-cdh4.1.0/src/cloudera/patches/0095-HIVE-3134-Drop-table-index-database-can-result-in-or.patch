From 738d9cab16ad9aed7668f90723b900c1bc3cf4bf Mon Sep 17 00:00:00 2001
From: Carl Steinbach <cws@apache.org>
Date: Sun, 17 Jun 2012 22:22:13 +0000
Subject: [PATCH 095/144] HIVE-3134 Drop table/index/database can result in orphaned locations
 (Kevin Wilfong via Carl Steinbach)

Summary:
Today when a managed table has a partition with a location which is not a subdirectory of the table's location, when the table is dropped the partition's data is not deleted from HDFS, resulting in an orphaned directory (the data exists but nothing points to it).

The same applies to dropping a database with cascade and a table has a location outside the database.

I think it is safe to assume managed tables/partitions own the directories they point to, so we should clean these up.

Test Plan: Added test cases to verify that the directories which would be orphaned are cleaned up by drop table/index/database.

Reviewers: JIRA, njain, cwsteinbach

Reviewed By: cwsteinbach

Differential Revision: https://reviews.facebook.net/D3633

git-svn-id: https://svn.apache.org/repos/asf/hive/trunk@1351174 13f79535-47bb-0310-9956-ffa450edef68
(cherry picked from commit 94cdb0e59a9b4d24a881515d27c838eaee319aea)
---
 .../hadoop/hive/metastore/HiveMetaStore.java       |  200 +++++++++++++++++++-
 .../apache/hadoop/hive/metastore/ObjectStore.java  |   22 +--
 .../drop_database_removes_partition_dirs.q         |   27 +++
 .../drop_index_removes_partition_dirs.q            |   22 +++
 .../drop_table_removes_partition_dirs.q            |   21 ++
 .../drop_database_removes_partition_dirs.q.out     |   61 ++++++
 .../drop_index_removes_partition_dirs.q.out        |   42 ++++
 .../drop_table_removes_partition_dirs.q.out        |   51 +++++
 8 files changed, 421 insertions(+), 25 deletions(-)
 create mode 100644 ql/src/test/queries/clientpositive/drop_database_removes_partition_dirs.q
 create mode 100644 ql/src/test/queries/clientpositive/drop_index_removes_partition_dirs.q
 create mode 100644 ql/src/test/queries/clientpositive/drop_table_removes_partition_dirs.q
 create mode 100644 ql/src/test/results/clientpositive/drop_database_removes_partition_dirs.q.out
 create mode 100644 ql/src/test/results/clientpositive/drop_index_removes_partition_dirs.q.out
 create mode 100644 ql/src/test/results/clientpositive/drop_table_removes_partition_dirs.q.out

diff --git a/src/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java b/src/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
index 26fd98e..7524484 100644
--- a/src/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
+++ b/src/metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java
@@ -606,6 +606,8 @@ public class HiveMetaStore extends ThriftHiveMetastore {
         IOException {
       boolean success = false;
       Database db = null;
+      List<Path> tablePaths = new ArrayList<Path>();
+      List<Path> partitionPaths = new ArrayList<Path>();
       try {
         ms.openTransaction();
         db = ms.getDatabase(name);
@@ -624,6 +626,60 @@ public class HiveMetaStore extends ThriftHiveMetastore {
               path + " is not writable by " +
               hiveConf.getUser());
         }
+
+        Path databasePath = wh.getDnsPath(wh.getDatabasePath(db));
+
+        // first drop tables
+        int tableBatchSize = HiveConf.getIntVar(hiveConf,
+            ConfVars.METASTORE_BATCH_RETRIEVE_MAX);
+
+        int startIndex = 0;
+        int endIndex = -1;
+        // retrieve the tables from the metastore in batches to alleviate memory constraints
+        while(endIndex < allTables.size() - 1) {
+          startIndex = endIndex + 1;
+          endIndex = endIndex + tableBatchSize;
+          if (endIndex >= allTables.size()) {
+            endIndex = allTables.size() - 1;
+          }
+
+          List<Table> tables = null;
+          try {
+            tables = ms.getTableObjectsByName(name, allTables.subList(startIndex, endIndex));
+          } catch (UnknownDBException e) {
+            throw new MetaException(e.getMessage());
+          }
+
+          if (tables != null && !tables.isEmpty()) {
+            for (Table table : tables) {
+
+              // If the table is not external and it might not be in a subdirectory of the database
+              // add it's locations to the list of paths to delete
+              Path tablePath = null;
+              if (table.getSd().getLocation() != null && !isExternal(table)) {
+                tablePath = wh.getDnsPath(new Path(table.getSd().getLocation()));
+                if (!wh.isWritable(tablePath.getParent())) {
+                  throw new MetaException("Database metadata not deleted since table: " +
+                      table.getTableName() + " has a parent location " +  tablePath.getParent() +
+                      " which is not writable by " + hiveConf.getUser());
+                }
+
+                if (!isSubdirectory(databasePath, tablePath)) {
+                  tablePaths.add(tablePath);
+                }
+              }
+
+              // For each partition in each table, drop the partitions and get a list of
+              // partitions' locations which might need to be deleted
+              partitionPaths = dropPartitionsAndGetLocations(ms, name, table.getTableName(),
+                  tablePath, table.getPartitionKeys(), deleteData && !isExternal(table));
+
+              // Drop the table but not its data
+              drop_table(name, table.getTableName(), false);
+            }
+          }
+        }
+
         if (ms.dropDatabase(name)) {
           success = ms.commitTransaction();
         }
@@ -631,7 +687,19 @@ public class HiveMetaStore extends ThriftHiveMetastore {
         if (!success) {
           ms.rollbackTransaction();
         } else if (deleteData) {
-          wh.deleteDir(new Path(db.getLocationUri()), true);
+          // Delete the data in the partitions which have other locations
+          deletePartitionData(partitionPaths);
+          // Delete the data in the tables which have other locations
+          for (Path tablePath : tablePaths) {
+            deleteTableData(tablePath);
+          }
+          // Delete the data in the database
+          try {
+            wh.deleteDir(new Path(db.getLocationUri()), true);
+          } catch (Exception e) {
+            LOG.error("Failed to delete database directory: " + db.getLocationUri() +
+                " " + e.getMessage());
+          }
           // it is not a terrible thing even if the data is not deleted
         }
         for (MetaStoreEventListener listener : listeners) {
@@ -640,6 +708,19 @@ public class HiveMetaStore extends ThriftHiveMetastore {
       }
     }
 
+    /**
+     * Returns a BEST GUESS as to whether or not other is a subdirectory of parent.  It does not
+     * take into account any intricacies of the underlying file system, which is assumed to be
+     * HDFS.  This should not return any false positives, but may return false negatives.
+     * @param parent
+     * @param other
+     * @return
+     */
+    private boolean isSubdirectory(Path parent, Path other) {
+      return other.toString().startsWith(parent.toString().endsWith(Path.SEPARATOR) ?
+          parent.toString() : parent.toString() + Path.SEPARATOR);
+    }
+
     public void drop_database(final String dbName, final boolean deleteData, final boolean cascade)
         throws NoSuchObjectException, InvalidOperationException, MetaException {
 
@@ -907,6 +988,7 @@ public class HiveMetaStore extends ThriftHiveMetastore {
       boolean success = false;
       boolean isExternal = false;
       Path tblPath = null;
+      List<Path> partPaths = null;
       Table tbl = null;
       isExternal = false;
       boolean isIndexTable = false;
@@ -958,6 +1040,10 @@ public class HiveMetaStore extends ThriftHiveMetastore {
           }
         }
 
+        // Drop the partitions and get a list of locations which need to be deleted
+        partPaths = dropPartitionsAndGetLocations(ms, dbname, name, tblPath,
+            tbl.getPartitionKeys(), deleteData && !isExternal);
+
         if (!ms.dropTable(dbname, name)) {
           throw new MetaException("Unable to drop table");
         }
@@ -965,8 +1051,11 @@ public class HiveMetaStore extends ThriftHiveMetastore {
       } finally {
         if (!success) {
           ms.rollbackTransaction();
-        } else if (deleteData && (tblPath != null) && !isExternal) {
-          wh.deleteDir(tblPath, true);
+        } else if (deleteData && !isExternal) {
+          // Delete the data in the partitions which have other locations
+          deletePartitionData(partPaths);
+          // Delete the data in the table
+          deleteTableData(tblPath);
           // ok even if the data is not deleted
         }
         for (MetaStoreEventListener listener : listeners) {
@@ -975,6 +1064,102 @@ public class HiveMetaStore extends ThriftHiveMetastore {
       }
     }
 
+    /**
+     * Deletes the data in a table's location, if it fails logs an error
+     *
+     * @param tablePath
+     */
+    private void deleteTableData(Path tablePath) {
+      if (tablePath != null) {
+        try {
+          wh.deleteDir(tablePath, true);
+        } catch (Exception e) {
+          LOG.error("Failed to delete table directory: " + tablePath +
+              " " + e.getMessage());
+        }
+      }
+    }
+
+    /**
+     * Give a list of partitions' locations, tries to delete each one
+     * and for each that fails logs an error.
+     *
+     * @param partPaths
+     */
+    private void deletePartitionData(List<Path> partPaths) {
+      if (partPaths != null && !partPaths.isEmpty()) {
+        for (Path partPath : partPaths) {
+          try {
+            wh.deleteDir(partPath, true);
+          } catch (Exception e) {
+            LOG.error("Failed to delete partition directory: " + partPath +
+                " " + e.getMessage());
+          }
+        }
+      }
+    }
+
+    /**
+     * Retrieves the partitions specified by partitionKeys.  If checkLocation, for locations of
+     * partitions which may not be subdirectories of tablePath checks to make the locations are
+     * writable.
+     *
+     * Drops the metadata for each partition.
+     *
+     * Provides a list of locations of partitions which may not be subdirectories of tablePath.
+     *
+     * @param ms
+     * @param dbName
+     * @param tableName
+     * @param tablePath
+     * @param partitionKeys
+     * @param checkLocation
+     * @return
+     * @throws MetaException
+     * @throws IOException
+     */
+    private List<Path> dropPartitionsAndGetLocations(RawStore ms, String dbName,
+        String tableName, Path tablePath, List<FieldSchema> partitionKeys, boolean checkLocation)
+            throws MetaException, IOException {
+
+      int partitionBatchSize = HiveConf.getIntVar(hiveConf,
+          ConfVars.METASTORE_BATCH_RETRIEVE_MAX);
+      Path tableDnsPath = null;
+      if (tablePath != null) {
+        tableDnsPath = wh.getDnsPath(tablePath);
+      }
+      List<Path> partPaths = new ArrayList<Path>();
+
+      // call dropPartition on each of the table's partitions to follow the
+      // procedure for cleanly dropping partitions.
+      while(true) {
+        List<Partition> partsToDelete = ms.getPartitions(dbName, tableName, partitionBatchSize);
+        if (partsToDelete == null || partsToDelete.isEmpty()) {
+          break;
+        }
+        for (Partition part : partsToDelete) {
+          if (checkLocation && part.getSd() != null &&
+              part.getSd().getLocation() != null) {
+
+            Path partPath = wh.getDnsPath(new Path(part.getSd().getLocation()));
+            if (tableDnsPath == null ||
+                (partPath != null && !isSubdirectory(tableDnsPath, partPath))){
+              if (!wh.isWritable(partPath.getParent())) {
+                  throw new MetaException("Table metadata not deleted since the partition " +
+                      Warehouse.makePartName(partitionKeys, part.getValues()) +
+                      " has parent location " + partPath.getParent() + " which is not writable " +
+                      "by " + hiveConf.getUser());
+               }
+              partPaths.add(partPath);
+            }
+          }
+          ms.dropPartition(dbName, tableName, part.getValues());
+        }
+      }
+
+      return partPaths;
+    }
+
     public void drop_table(final String dbname, final String name, final boolean deleteData)
         throws NoSuchObjectException, MetaException {
       startTableFunction("drop_table", dbname, name);
@@ -2149,6 +2334,7 @@ public class HiveMetaStore extends ThriftHiveMetastore {
 
       boolean success = false;
       Path tblPath = null;
+      List<Path> partPaths = null;
       try {
         ms.openTransaction();
 
@@ -2175,6 +2361,11 @@ public class HiveMetaStore extends ThriftHiveMetastore {
                   hiveConf.getUser());
             }
           }
+
+          // Drop the partitions and get a list of partition locations which need to be deleted
+          partPaths = dropPartitionsAndGetLocations(ms, dbName, idxTblName, tblPath,
+              tbl.getPartitionKeys(), deleteData);
+
           if (!ms.dropTable(dbName, idxTblName)) {
             throw new MetaException("Unable to drop underlying data table "
                 + idxTblName + " for index " + idxTblName);
@@ -2186,7 +2377,8 @@ public class HiveMetaStore extends ThriftHiveMetastore {
           ms.rollbackTransaction();
           return false;
         } else if (deleteData && tblPath != null) {
-          wh.deleteDir(tblPath, true);
+          deletePartitionData(partPaths);
+          deleteTableData(tblPath);
           // ok even if the data is not deleted
         }
       }
diff --git a/src/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java b/src/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java
index a156eaa..6f4716c 100644
--- a/src/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java
+++ b/src/metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java
@@ -456,11 +456,6 @@ public class ObjectStore implements RawStore, Configurable {
     try {
       openTransaction();
 
-      // first drop tables
-      for (String tableName : getAllTables(dbname)) {
-        dropTable(dbname, tableName);
-      }
-
       // then drop the database
       MDatabase db = getMDatabase(dbname);
       pm.retrieve(db);
@@ -681,7 +676,7 @@ public class ObjectStore implements RawStore, Configurable {
       MTable tbl = getMTable(dbName, tableName);
       pm.retrieve(tbl);
       if (tbl != null) {
-        // first remove all the partitions
+        // first remove all the grants
         List<MTablePrivilege> tabGrants = listAllTableGrants(dbName, tableName);
         if (tabGrants != null && tabGrants.size() > 0) {
           pm.deletePersistentAll(tabGrants);
@@ -703,21 +698,6 @@ public class ObjectStore implements RawStore, Configurable {
           pm.deletePersistentAll(partColGrants);
         }
 
-        int partitionBatchSize = HiveConf.getIntVar(getConf(),
-          ConfVars.METASTORE_BATCH_RETRIEVE_TABLE_PARTITION_MAX);
-
-        // call dropPartition on each of the table's partitions to follow the
-        // procedure for cleanly dropping partitions.
-        while(true) {
-          List<MPartition> partsToDelete = listMPartitions(dbName, tableName, partitionBatchSize);
-          if (partsToDelete == null || partsToDelete.isEmpty()) {
-            break;
-          }
-          for (MPartition mpart : partsToDelete) {
-            dropPartitionCommon(mpart);
-          }
-        }
-
         preDropStorageDescriptor(tbl.getSd());
         // then remove the table
         pm.deletePersistentAll(tbl);
diff --git a/src/ql/src/test/queries/clientpositive/drop_database_removes_partition_dirs.q b/src/ql/src/test/queries/clientpositive/drop_database_removes_partition_dirs.q
new file mode 100644
index 0000000..a5f5189
--- /dev/null
+++ b/src/ql/src/test/queries/clientpositive/drop_database_removes_partition_dirs.q
@@ -0,0 +1,27 @@
+-- This test verifies that if a partition exists outside a table's current location when the
+-- database is dropped the partition's location is dropped as well.
+
+CREATE DATABASE test_database;
+
+USE test_database;
+
+CREATE TABLE test_table (key STRING, value STRING)
+PARTITIONED BY (part STRING)
+STORED AS RCFILE
+LOCATION 'file:${system:test.tmp.dir}/drop_database_removes_partition_dirs_table';
+
+ALTER TABLE test_table ADD PARTITION (part = '1')
+LOCATION 'file:${system:test.tmp.dir}/drop_database_removes_partition_dirs_table2/part=1';
+
+INSERT OVERWRITE TABLE test_table PARTITION (part = '1')
+SELECT * FROM default.src;
+
+dfs -ls ${system:test.tmp.dir}/drop_database_removes_partition_dirs_table2;
+
+USE default;
+
+DROP DATABASE test_database CASCADE;
+
+dfs -ls ${system:test.tmp.dir}/drop_database_removes_partition_dirs_table2;
+
+dfs -rmr ${system:test.tmp.dir}/drop_database_removes_partition_dirs_table2;
diff --git a/src/ql/src/test/queries/clientpositive/drop_index_removes_partition_dirs.q b/src/ql/src/test/queries/clientpositive/drop_index_removes_partition_dirs.q
new file mode 100644
index 0000000..ed471db
--- /dev/null
+++ b/src/ql/src/test/queries/clientpositive/drop_index_removes_partition_dirs.q
@@ -0,0 +1,22 @@
+-- This test verifies that if a partition exists outside an index table's current location when the
+-- index is dropped the partition's location is dropped as well.
+
+CREATE TABLE test_table (key STRING, value STRING)
+PARTITIONED BY (part STRING)
+STORED AS RCFILE
+LOCATION 'file:${system:test.tmp.dir}/drop_database_removes_partition_dirs_table';
+
+CREATE INDEX test_index ON 
+TABLE test_table(key) AS 'compact' WITH DEFERRED REBUILD
+IN TABLE test_index_table;
+
+ALTER TABLE test_index_table ADD PARTITION (part = '1')
+LOCATION 'file:${system:test.tmp.dir}/drop_index_removes_partition_dirs_index_table2/part=1';
+
+dfs -ls ${system:test.tmp.dir}/drop_index_removes_partition_dirs_index_table2;
+
+DROP INDEX test_index ON test_table;
+
+dfs -ls ${system:test.tmp.dir}/drop_index_removes_partition_dirs_index_table2;
+
+dfs -rmr ${system:test.tmp.dir}/drop_index_removes_partition_dirs_index_table2;
diff --git a/src/ql/src/test/queries/clientpositive/drop_table_removes_partition_dirs.q b/src/ql/src/test/queries/clientpositive/drop_table_removes_partition_dirs.q
new file mode 100644
index 0000000..102b3ef
--- /dev/null
+++ b/src/ql/src/test/queries/clientpositive/drop_table_removes_partition_dirs.q
@@ -0,0 +1,21 @@
+-- This test verifies that if a partition exists outside the table's current location when the
+-- table is dropped the partition's location is dropped as well.
+
+CREATE TABLE test_table (key STRING, value STRING)
+PARTITIONED BY (part STRING)
+STORED AS RCFILE
+LOCATION 'file:${system:test.tmp.dir}/drop_table_removes_partition_dirs_table';
+
+ALTER TABLE test_table ADD PARTITION (part = '1')
+LOCATION 'file:${system:test.tmp.dir}/drop_table_removes_partition_dirs_table2/part=1';
+
+INSERT OVERWRITE TABLE test_table PARTITION (part = '1')
+SELECT * FROM src;
+
+dfs -ls ${system:test.tmp.dir}/drop_table_removes_partition_dirs_table2;
+
+DROP TABLE test_table;
+
+dfs -ls ${system:test.tmp.dir}/drop_table_removes_partition_dirs_table2;
+
+dfs -rmr ${system:test.tmp.dir}/drop_table_removes_partition_dirs_table2;
diff --git a/src/ql/src/test/results/clientpositive/drop_database_removes_partition_dirs.q.out b/src/ql/src/test/results/clientpositive/drop_database_removes_partition_dirs.q.out
new file mode 100644
index 0000000..e2f32b5
--- /dev/null
+++ b/src/ql/src/test/results/clientpositive/drop_database_removes_partition_dirs.q.out
@@ -0,0 +1,61 @@
+PREHOOK: query: -- This test verifies that if a partition exists outside a table's current location when the
+-- database is dropped the partition's location is dropped as well.
+
+CREATE DATABASE test_database
+PREHOOK: type: CREATEDATABASE
+POSTHOOK: query: -- This test verifies that if a partition exists outside a table's current location when the
+-- database is dropped the partition's location is dropped as well.
+
+CREATE DATABASE test_database
+POSTHOOK: type: CREATEDATABASE
+PREHOOK: query: USE test_database
+PREHOOK: type: SWITCHDATABASE
+POSTHOOK: query: USE test_database
+POSTHOOK: type: SWITCHDATABASE
+PREHOOK: query: CREATE TABLE test_table (key STRING, value STRING)
+PARTITIONED BY (part STRING)
+STORED AS RCFILE
+#### A masked pattern was here ####
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: CREATE TABLE test_table (key STRING, value STRING)
+PARTITIONED BY (part STRING)
+STORED AS RCFILE
+#### A masked pattern was here ####
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: test_database@test_table
+PREHOOK: query: ALTER TABLE test_table ADD PARTITION (part = '1')
+#### A masked pattern was here ####
+PREHOOK: type: ALTERTABLE_ADDPARTS
+PREHOOK: Input: test_database@test_table
+POSTHOOK: query: ALTER TABLE test_table ADD PARTITION (part = '1')
+#### A masked pattern was here ####
+POSTHOOK: type: ALTERTABLE_ADDPARTS
+POSTHOOK: Input: test_database@test_table
+POSTHOOK: Output: test_database@test_table@part=1
+PREHOOK: query: INSERT OVERWRITE TABLE test_table PARTITION (part = '1')
+SELECT * FROM default.src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: test_database@test_table@part=1
+POSTHOOK: query: INSERT OVERWRITE TABLE test_table PARTITION (part = '1')
+SELECT * FROM default.src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: test_database@test_table@part=1
+POSTHOOK: Lineage: test_table PARTITION(part=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: test_table PARTITION(part=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+Found 1 items
+#### A masked pattern was here ####
+PREHOOK: query: USE default
+PREHOOK: type: SWITCHDATABASE
+POSTHOOK: query: USE default
+POSTHOOK: type: SWITCHDATABASE
+POSTHOOK: Lineage: test_table PARTITION(part=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: test_table PARTITION(part=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+PREHOOK: query: DROP DATABASE test_database CASCADE
+PREHOOK: type: DROPDATABASE
+POSTHOOK: query: DROP DATABASE test_database CASCADE
+POSTHOOK: type: DROPDATABASE
+POSTHOOK: Lineage: test_table PARTITION(part=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: test_table PARTITION(part=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+#### A masked pattern was here ####
diff --git a/src/ql/src/test/results/clientpositive/drop_index_removes_partition_dirs.q.out b/src/ql/src/test/results/clientpositive/drop_index_removes_partition_dirs.q.out
new file mode 100644
index 0000000..2bb0e22
--- /dev/null
+++ b/src/ql/src/test/results/clientpositive/drop_index_removes_partition_dirs.q.out
@@ -0,0 +1,42 @@
+PREHOOK: query: -- This test verifies that if a partition exists outside an index table's current location when the
+-- index is dropped the partition's location is dropped as well.
+
+CREATE TABLE test_table (key STRING, value STRING)
+PARTITIONED BY (part STRING)
+STORED AS RCFILE
+#### A masked pattern was here ####
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: -- This test verifies that if a partition exists outside an index table's current location when the
+-- index is dropped the partition's location is dropped as well.
+
+CREATE TABLE test_table (key STRING, value STRING)
+PARTITIONED BY (part STRING)
+STORED AS RCFILE
+#### A masked pattern was here ####
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@test_table
+PREHOOK: query: CREATE INDEX test_index ON 
+TABLE test_table(key) AS 'compact' WITH DEFERRED REBUILD
+IN TABLE test_index_table
+PREHOOK: type: CREATEINDEX
+POSTHOOK: query: CREATE INDEX test_index ON 
+TABLE test_table(key) AS 'compact' WITH DEFERRED REBUILD
+IN TABLE test_index_table
+POSTHOOK: type: CREATEINDEX
+POSTHOOK: Output: default@test_index_table
+PREHOOK: query: ALTER TABLE test_index_table ADD PARTITION (part = '1')
+#### A masked pattern was here ####
+PREHOOK: type: ALTERTABLE_ADDPARTS
+PREHOOK: Input: default@test_index_table
+POSTHOOK: query: ALTER TABLE test_index_table ADD PARTITION (part = '1')
+#### A masked pattern was here ####
+POSTHOOK: type: ALTERTABLE_ADDPARTS
+POSTHOOK: Input: default@test_index_table
+POSTHOOK: Output: default@test_index_table@part=1
+Found 1 items
+#### A masked pattern was here ####
+PREHOOK: query: DROP INDEX test_index ON test_table
+PREHOOK: type: DROPINDEX
+POSTHOOK: query: DROP INDEX test_index ON test_table
+POSTHOOK: type: DROPINDEX
+#### A masked pattern was here ####
diff --git a/src/ql/src/test/results/clientpositive/drop_table_removes_partition_dirs.q.out b/src/ql/src/test/results/clientpositive/drop_table_removes_partition_dirs.q.out
new file mode 100644
index 0000000..6cc545b
--- /dev/null
+++ b/src/ql/src/test/results/clientpositive/drop_table_removes_partition_dirs.q.out
@@ -0,0 +1,51 @@
+PREHOOK: query: -- This test verifies that if a partition exists outside the table's current location when the
+-- table is dropped the partition's location is dropped as well.
+
+CREATE TABLE test_table (key STRING, value STRING)
+PARTITIONED BY (part STRING)
+STORED AS RCFILE
+#### A masked pattern was here ####
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: -- This test verifies that if a partition exists outside the table's current location when the
+-- table is dropped the partition's location is dropped as well.
+
+CREATE TABLE test_table (key STRING, value STRING)
+PARTITIONED BY (part STRING)
+STORED AS RCFILE
+#### A masked pattern was here ####
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@test_table
+PREHOOK: query: ALTER TABLE test_table ADD PARTITION (part = '1')
+#### A masked pattern was here ####
+PREHOOK: type: ALTERTABLE_ADDPARTS
+PREHOOK: Input: default@test_table
+POSTHOOK: query: ALTER TABLE test_table ADD PARTITION (part = '1')
+#### A masked pattern was here ####
+POSTHOOK: type: ALTERTABLE_ADDPARTS
+POSTHOOK: Input: default@test_table
+POSTHOOK: Output: default@test_table@part=1
+PREHOOK: query: INSERT OVERWRITE TABLE test_table PARTITION (part = '1')
+SELECT * FROM src
+PREHOOK: type: QUERY
+PREHOOK: Input: default@src
+PREHOOK: Output: default@test_table@part=1
+POSTHOOK: query: INSERT OVERWRITE TABLE test_table PARTITION (part = '1')
+SELECT * FROM src
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@src
+POSTHOOK: Output: default@test_table@part=1
+POSTHOOK: Lineage: test_table PARTITION(part=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: test_table PARTITION(part=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+Found 1 items
+#### A masked pattern was here ####
+PREHOOK: query: DROP TABLE test_table
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: default@test_table
+PREHOOK: Output: default@test_table
+POSTHOOK: query: DROP TABLE test_table
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: default@test_table
+POSTHOOK: Output: default@test_table
+POSTHOOK: Lineage: test_table PARTITION(part=1).key SIMPLE [(src)src.FieldSchema(name:key, type:string, comment:default), ]
+POSTHOOK: Lineage: test_table PARTITION(part=1).value SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
+#### A masked pattern was here ####
-- 
1.7.0.4

