From 87acceaecf8e72097e6fc514be7b0f741c0ddc61 Mon Sep 17 00:00:00 2001
From: Kevin Wilfong <kevinwilfong@apache.org>
Date: Thu, 31 May 2012 16:31:53 +0000
Subject: [PATCH 072/148] HIVE-3063. drop partition for non-string columns is failing (njain via kevinwilfong)

git-svn-id: https://svn.apache.org/repos/asf/hive/trunk@1344801 13f79535-47bb-0310-9956-ffa450edef68
(cherry picked from commit 4ce656933d6d8ff7bd99348dfefc77fb8e85f44f)
---
 .../java/org/apache/hadoop/hive/ql/ErrorMsg.java   |    2 +
 .../org/apache/hadoop/hive/ql/exec/DDLTask.java    |   16 ++-
 .../hadoop/hive/ql/parse/DDLSemanticAnalyzer.java  |   53 ++++++++--
 .../apache/hadoop/hive/ql/plan/DropTableDesc.java  |   19 +++-
 .../apache/hadoop/hive/ql/plan/PartitionSpec.java  |   29 +++++-
 .../drop_partition_filter_failure2.q               |   11 ++
 .../clientpositive/drop_partitions_filter2.q       |   20 ++++
 .../drop_partition_filter_failure2.q.out           |   34 ++++++
 .../clientpositive/drop_partitions_filter2.q.out   |  107 ++++++++++++++++++++
 9 files changed, 274 insertions(+), 17 deletions(-)
 create mode 100644 ql/src/test/queries/clientnegative/drop_partition_filter_failure2.q
 create mode 100644 ql/src/test/queries/clientpositive/drop_partitions_filter2.q
 create mode 100644 ql/src/test/results/clientnegative/drop_partition_filter_failure2.q.out
 create mode 100644 ql/src/test/results/clientpositive/drop_partitions_filter2.q.out

diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java b/src/ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java
index 4d770dd..f7032b0 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/ErrorMsg.java
@@ -213,6 +213,8 @@ public enum ErrorMsg {
   INSERT_INTO_DYNAMICPARTITION_IFNOTEXISTS(10127,
       "Dynamic partitions do not support IF NOT EXISTS. Specified partitions with value :"),
   UDAF_INVALID_LOCATION(10128, "Not yet supported place for UDAF"),
+  DROP_PARTITION_NON_STRING_PARTCOLS_NONEQUALITY(10129,
+    "Drop partitions for a non string partition columns is not allowed using non-equality"),
 
   SCRIPT_INIT_ERROR(20000, "Unable to initialize custom script."),
   SCRIPT_IO_ERROR(20001, "An error occurred while reading or writing to your custom script. "
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java b/src/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
index aace1fa..603ebed 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java
@@ -3086,11 +3086,19 @@ public class DDLTask extends Task<DDLWork> implements Serializable {
       List<Partition> partsToDelete = new ArrayList<Partition>();
       for (PartitionSpec partSpec : dropTbl.getPartSpecs()) {
         List<Partition> partitions = null;
-        try {
-          partitions = db.getPartitionsByFilter(tbl, partSpec.toString());
-        } catch (Exception e) {
-          throw new HiveException(e);
+        // getPartitionsByFilter only works for string columns.
+        // Till that is fixed, only equality will work for non-string columns.
+        if (dropTbl.isStringPartitionColumns()) {
+          try {
+            partitions = db.getPartitionsByFilter(tbl, partSpec.toString());
+          } catch (Exception e) {
+            throw new HiveException(e);
+          }
+        }
+        else {
+          partitions = db.getPartitions(tbl, partSpec.getPartSpecWithoutOperator());
         }
+
         // this is to prevent dropping archived partition which is archived in a
         // different level the drop command specified.
         int partPrefixToDrop = 0;
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java
index 42e83d1..182faf2 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java
@@ -713,7 +713,7 @@ public class DDLSemanticAnalyzer extends BaseSemanticAnalyzer {
     }
 
     DropTableDesc dropTblDesc = new DropTableDesc(
-      tableName, expectView, ifExists);
+      tableName, expectView, ifExists, true);
     rootTasks.add(TaskFactory.get(new DDLWork(getInputs(), getOutputs(),
         dropTblDesc), conf));
   }
@@ -1790,11 +1790,10 @@ public class DDLSemanticAnalyzer extends BaseSemanticAnalyzer {
     String tblName = getUnescapedName((ASTNode)ast.getChild(0));
     // get table metadata
     List<PartitionSpec> partSpecs = getFullPartitionSpecs(ast);
-    DropTableDesc dropTblDesc =
-      new DropTableDesc(tblName, partSpecs, expectView);
+    Table tab = null;
 
     try {
-      Table tab = db.getTable(db.getCurrentDatabase(), tblName, false);
+      tab = db.getTable(db.getCurrentDatabase(), tblName, false);
       if (tab != null) {
         inputs.add(new ReadEntity(tab));
       }
@@ -1802,15 +1801,39 @@ public class DDLSemanticAnalyzer extends BaseSemanticAnalyzer {
       throw new SemanticException(ErrorMsg.INVALID_TABLE.getMsg(tblName));
     }
 
+    // Find out if all partition columns are strings. This is needed for JDO
+    boolean stringPartitionColumns = true;
+    List<FieldSchema> partCols = tab.getPartCols();
+
+    for (FieldSchema partCol : partCols) {
+      if (!partCol.getType().toLowerCase().equals("string")) {
+        stringPartitionColumns = false;
+        break;
+      }
+    }
+
+    // Only equality is supported for non-string partition columns
+    if (!stringPartitionColumns) {
+      for (PartitionSpec partSpec : partSpecs) {
+        if (partSpec.isNonEqualityOperator()) {
+          throw new SemanticException(
+            ErrorMsg.DROP_PARTITION_NON_STRING_PARTCOLS_NONEQUALITY.getMsg());
+        }
+      }
+    }
+
     if (partSpecs != null) {
       boolean ifExists = (ast.getFirstChildWithType(TOK_IFEXISTS) != null);
       // we want to signal an error if the partition doesn't exist and we're
       // configured not to fail silently
       boolean throwException =
         !ifExists && !HiveConf.getBoolVar(conf, ConfVars.DROPIGNORESNONEXISTENT);
-      addTableDropPartsOutputs(tblName, partSpecs, throwException);
+      addTableDropPartsOutputs(tblName, partSpecs, throwException, stringPartitionColumns);
     }
 
+    DropTableDesc dropTblDesc =
+        new DropTableDesc(tblName, partSpecs, expectView, stringPartitionColumns);
+
     rootTasks.add(TaskFactory.get(new DDLWork(getInputs(), getOutputs(),
         dropTblDesc), conf));
   }
@@ -2218,7 +2241,7 @@ public class DDLSemanticAnalyzer extends BaseSemanticAnalyzer {
    * throwIfNonExistent is true, otherwise ignore it.
    */
   private void addTableDropPartsOutputs(String tblName, List<PartitionSpec> partSpecs,
-            boolean throwIfNonExistent)
+            boolean throwIfNonExistent, boolean stringPartitionColumns)
     throws SemanticException {
     Table tab;
     try {
@@ -2232,11 +2255,21 @@ public class DDLSemanticAnalyzer extends BaseSemanticAnalyzer {
     for (i = partSpecs.iterator(), index = 1; i.hasNext(); ++index) {
       PartitionSpec partSpec = i.next();
       List<Partition> parts = null;
-      try {
-        parts = db.getPartitionsByFilter(tab, partSpec.toString());
-      } catch (Exception e) {
-          throw new SemanticException(ErrorMsg.INVALID_PARTITION.getMsg(partSpec.toString()), e);
+      if (stringPartitionColumns) {
+        try {
+          parts = db.getPartitionsByFilter(tab, partSpec.toString());
+        } catch (Exception e) {
+            throw new SemanticException(ErrorMsg.INVALID_PARTITION.getMsg(partSpec.toString()), e);
+        }
+      }
+      else {
+        try {
+          parts = db.getPartitions(tab, partSpec.getPartSpecWithoutOperator());
+        } catch (Exception e) {
+            throw new SemanticException(ErrorMsg.INVALID_PARTITION.getMsg(partSpec.toString()), e);
+        }
       }
+
       if (parts.isEmpty()) {
         if(throwIfNonExistent) {
           throw new SemanticException(ErrorMsg.INVALID_PARTITION.getMsg(partSpec.toString()));
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/plan/DropTableDesc.java b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/DropTableDesc.java
index 67827cc..f37976e 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/plan/DropTableDesc.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/DropTableDesc.java
@@ -34,6 +34,9 @@ public class DropTableDesc extends DDLDesc implements Serializable {
   ArrayList<PartitionSpec> partSpecs;
   boolean expectView;
   boolean ifExists;
+  boolean stringPartitionColumns; // This is due to JDO not working very well with
+                                  // non-string partition columns.
+                                  // We need a different codepath for them
 
   public DropTableDesc() {
   }
@@ -41,14 +44,17 @@ public class DropTableDesc extends DDLDesc implements Serializable {
   /**
    * @param tableName
    */
-  public DropTableDesc(String tableName, boolean expectView, boolean ifExists) {
+  public DropTableDesc(String tableName, boolean expectView,
+                       boolean ifExists, boolean stringPartitionColumns) {
     this.tableName = tableName;
     partSpecs = null;
     this.expectView = expectView;
     this.ifExists = ifExists;
+    this.stringPartitionColumns = stringPartitionColumns;
   }
 
-  public DropTableDesc(String tableName, List<PartitionSpec> partSpecs, boolean expectView) {
+  public DropTableDesc(String tableName, List<PartitionSpec> partSpecs,
+                       boolean expectView, boolean stringPartitionColumns) {
 
     this.tableName = tableName;
     this.partSpecs = new ArrayList<PartitionSpec>(partSpecs.size());
@@ -56,6 +62,7 @@ public class DropTableDesc extends DDLDesc implements Serializable {
       this.partSpecs.add(partSpecs.get(i));
     }
     this.expectView = expectView;
+    this.stringPartitionColumns = stringPartitionColumns;
   }
 
   /**
@@ -118,4 +125,12 @@ public class DropTableDesc extends DDLDesc implements Serializable {
   public void setIfExists(boolean ifExists) {
     this.ifExists = ifExists;
   }
+
+  public boolean isStringPartitionColumns() {
+    return stringPartitionColumns;
+  }
+
+  public void setStringPartitionColumns(boolean stringPartitionColumns) {
+    this.stringPartitionColumns = stringPartitionColumns;
+  }
 }
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/plan/PartitionSpec.java b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/PartitionSpec.java
index 9bcdbc3..ef1c3c9 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/plan/PartitionSpec.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/plan/PartitionSpec.java
@@ -18,6 +18,8 @@
 
 package org.apache.hadoop.hive.ql.plan;
 
+import java.util.HashMap;
+import java.util.Iterator;
 import java.util.LinkedHashMap;
 import java.util.Map;
 
@@ -62,7 +64,7 @@ public class PartitionSpec {
     }
   }
 
-  private Map<String, PredicateSpec> partSpec;
+  private final Map<String, PredicateSpec> partSpec;
 
   public PartitionSpec() {
     this.partSpec = new LinkedHashMap<String, PredicateSpec>();
@@ -102,4 +104,29 @@ public class PartitionSpec {
     }
     return filterString.toString();
   }
+
+  // getParitionsByFilter only works for string columns due to a JDO limitation.
+  // The operator is only useful if it can be passed as a filter to the metastore.
+  // For compatibility with other non-string partition columns, this function
+  // returns the key, value mapping assuming that the operator is equality.
+  public Map<String, String> getPartSpecWithoutOperator() {
+    Map<String, String> partSpec = new HashMap<String, String>();
+    for (Map.Entry<String, PredicateSpec> entry: this.partSpec.entrySet()) {
+      partSpec.put(entry.getKey(), entry.getValue().getValue());
+    }
+
+    return partSpec;
+  }
+
+  // Again, for the same reason as the above function - getPartSpecWithoutOperator
+  public boolean isNonEqualityOperator() {
+    Iterator<PredicateSpec> iter = partSpec.values().iterator();
+    while (iter.hasNext()) {
+      PredicateSpec predSpec = iter.next();
+      if (!predSpec.operator.equals("=")) {
+        return true;
+      }
+    }
+    return false;
+  }
 }
diff --git a/src/ql/src/test/queries/clientnegative/drop_partition_filter_failure2.q b/src/ql/src/test/queries/clientnegative/drop_partition_filter_failure2.q
new file mode 100644
index 0000000..4d238d7
--- /dev/null
+++ b/src/ql/src/test/queries/clientnegative/drop_partition_filter_failure2.q
@@ -0,0 +1,11 @@
+create table ptestfilter (a string, b int) partitioned by (c string, d int);
+describe ptestfilter;
+
+alter table ptestfilter add partition (c='US', d=1);
+alter table ptestfilter add partition (c='US', d=2);
+show partitions ptestfilter;
+
+alter table ptestfilter drop partition (c='US', d<'2');
+
+
+
diff --git a/src/ql/src/test/queries/clientpositive/drop_partitions_filter2.q b/src/ql/src/test/queries/clientpositive/drop_partitions_filter2.q
new file mode 100644
index 0000000..798aa6d
--- /dev/null
+++ b/src/ql/src/test/queries/clientpositive/drop_partitions_filter2.q
@@ -0,0 +1,20 @@
+create table ptestfilter (a string, b int) partitioned by (c int, d int);
+describe ptestfilter;
+
+alter table ptestfilter add partition (c=1, d=1);
+alter table ptestfilter add partition (c=1, d=2);
+alter table ptestFilter add partition (c=2, d=1);
+alter table ptestfilter add partition (c=2, d=2);
+alter table ptestfilter add partition (c=3, d=1);
+alter table ptestfilter add partition (c=3, d=2);
+show partitions ptestfilter;
+
+alter table ptestfilter drop partition (c=1, d=1);
+show partitions ptestfilter;
+
+alter table ptestfilter drop partition (c=2);
+show partitions ptestfilter;
+
+drop table ptestfilter;
+
+
diff --git a/src/ql/src/test/results/clientnegative/drop_partition_filter_failure2.q.out b/src/ql/src/test/results/clientnegative/drop_partition_filter_failure2.q.out
new file mode 100644
index 0000000..405015c
--- /dev/null
+++ b/src/ql/src/test/results/clientnegative/drop_partition_filter_failure2.q.out
@@ -0,0 +1,34 @@
+PREHOOK: query: create table ptestfilter (a string, b int) partitioned by (c string, d int)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table ptestfilter (a string, b int) partitioned by (c string, d int)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@ptestfilter
+PREHOOK: query: describe ptestfilter
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe ptestfilter
+POSTHOOK: type: DESCTABLE
+a	string	
+b	int	
+c	string	
+d	int	
+PREHOOK: query: alter table ptestfilter add partition (c='US', d=1)
+PREHOOK: type: ALTERTABLE_ADDPARTS
+PREHOOK: Input: default@ptestfilter
+POSTHOOK: query: alter table ptestfilter add partition (c='US', d=1)
+POSTHOOK: type: ALTERTABLE_ADDPARTS
+POSTHOOK: Input: default@ptestfilter
+POSTHOOK: Output: default@ptestfilter@c=US/d=1
+PREHOOK: query: alter table ptestfilter add partition (c='US', d=2)
+PREHOOK: type: ALTERTABLE_ADDPARTS
+PREHOOK: Input: default@ptestfilter
+POSTHOOK: query: alter table ptestfilter add partition (c='US', d=2)
+POSTHOOK: type: ALTERTABLE_ADDPARTS
+POSTHOOK: Input: default@ptestfilter
+POSTHOOK: Output: default@ptestfilter@c=US/d=2
+PREHOOK: query: show partitions ptestfilter
+PREHOOK: type: SHOWPARTITIONS
+POSTHOOK: query: show partitions ptestfilter
+POSTHOOK: type: SHOWPARTITIONS
+c=US/d=1
+c=US/d=2
+FAILED: SemanticException [Error 10129]: Drop partitions for a non string partition columns is not allowed using non-equality
diff --git a/src/ql/src/test/results/clientpositive/drop_partitions_filter2.q.out b/src/ql/src/test/results/clientpositive/drop_partitions_filter2.q.out
new file mode 100644
index 0000000..10f45b3
--- /dev/null
+++ b/src/ql/src/test/results/clientpositive/drop_partitions_filter2.q.out
@@ -0,0 +1,107 @@
+PREHOOK: query: create table ptestfilter (a string, b int) partitioned by (c int, d int)
+PREHOOK: type: CREATETABLE
+POSTHOOK: query: create table ptestfilter (a string, b int) partitioned by (c int, d int)
+POSTHOOK: type: CREATETABLE
+POSTHOOK: Output: default@ptestfilter
+PREHOOK: query: describe ptestfilter
+PREHOOK: type: DESCTABLE
+POSTHOOK: query: describe ptestfilter
+POSTHOOK: type: DESCTABLE
+a	string	
+b	int	
+c	int	
+d	int	
+PREHOOK: query: alter table ptestfilter add partition (c=1, d=1)
+PREHOOK: type: ALTERTABLE_ADDPARTS
+PREHOOK: Input: default@ptestfilter
+POSTHOOK: query: alter table ptestfilter add partition (c=1, d=1)
+POSTHOOK: type: ALTERTABLE_ADDPARTS
+POSTHOOK: Input: default@ptestfilter
+POSTHOOK: Output: default@ptestfilter@c=1/d=1
+PREHOOK: query: alter table ptestfilter add partition (c=1, d=2)
+PREHOOK: type: ALTERTABLE_ADDPARTS
+PREHOOK: Input: default@ptestfilter
+POSTHOOK: query: alter table ptestfilter add partition (c=1, d=2)
+POSTHOOK: type: ALTERTABLE_ADDPARTS
+POSTHOOK: Input: default@ptestfilter
+POSTHOOK: Output: default@ptestfilter@c=1/d=2
+PREHOOK: query: alter table ptestFilter add partition (c=2, d=1)
+PREHOOK: type: ALTERTABLE_ADDPARTS
+PREHOOK: Input: default@ptestfilter
+POSTHOOK: query: alter table ptestFilter add partition (c=2, d=1)
+POSTHOOK: type: ALTERTABLE_ADDPARTS
+POSTHOOK: Input: default@ptestfilter
+POSTHOOK: Output: default@ptestfilter@c=2/d=1
+PREHOOK: query: alter table ptestfilter add partition (c=2, d=2)
+PREHOOK: type: ALTERTABLE_ADDPARTS
+PREHOOK: Input: default@ptestfilter
+POSTHOOK: query: alter table ptestfilter add partition (c=2, d=2)
+POSTHOOK: type: ALTERTABLE_ADDPARTS
+POSTHOOK: Input: default@ptestfilter
+POSTHOOK: Output: default@ptestfilter@c=2/d=2
+PREHOOK: query: alter table ptestfilter add partition (c=3, d=1)
+PREHOOK: type: ALTERTABLE_ADDPARTS
+PREHOOK: Input: default@ptestfilter
+POSTHOOK: query: alter table ptestfilter add partition (c=3, d=1)
+POSTHOOK: type: ALTERTABLE_ADDPARTS
+POSTHOOK: Input: default@ptestfilter
+POSTHOOK: Output: default@ptestfilter@c=3/d=1
+PREHOOK: query: alter table ptestfilter add partition (c=3, d=2)
+PREHOOK: type: ALTERTABLE_ADDPARTS
+PREHOOK: Input: default@ptestfilter
+POSTHOOK: query: alter table ptestfilter add partition (c=3, d=2)
+POSTHOOK: type: ALTERTABLE_ADDPARTS
+POSTHOOK: Input: default@ptestfilter
+POSTHOOK: Output: default@ptestfilter@c=3/d=2
+PREHOOK: query: show partitions ptestfilter
+PREHOOK: type: SHOWPARTITIONS
+POSTHOOK: query: show partitions ptestfilter
+POSTHOOK: type: SHOWPARTITIONS
+c=1/d=1
+c=1/d=2
+c=2/d=1
+c=2/d=2
+c=3/d=1
+c=3/d=2
+PREHOOK: query: alter table ptestfilter drop partition (c=1, d=1)
+PREHOOK: type: ALTERTABLE_DROPPARTS
+PREHOOK: Input: default@ptestfilter
+PREHOOK: Output: default@ptestfilter@c=1/d=1
+POSTHOOK: query: alter table ptestfilter drop partition (c=1, d=1)
+POSTHOOK: type: ALTERTABLE_DROPPARTS
+POSTHOOK: Input: default@ptestfilter
+POSTHOOK: Output: default@ptestfilter@c=1/d=1
+PREHOOK: query: show partitions ptestfilter
+PREHOOK: type: SHOWPARTITIONS
+POSTHOOK: query: show partitions ptestfilter
+POSTHOOK: type: SHOWPARTITIONS
+c=1/d=2
+c=2/d=1
+c=2/d=2
+c=3/d=1
+c=3/d=2
+PREHOOK: query: alter table ptestfilter drop partition (c=2)
+PREHOOK: type: ALTERTABLE_DROPPARTS
+PREHOOK: Input: default@ptestfilter
+PREHOOK: Output: default@ptestfilter@c=2/d=1
+PREHOOK: Output: default@ptestfilter@c=2/d=2
+POSTHOOK: query: alter table ptestfilter drop partition (c=2)
+POSTHOOK: type: ALTERTABLE_DROPPARTS
+POSTHOOK: Input: default@ptestfilter
+POSTHOOK: Output: default@ptestfilter@c=2/d=1
+POSTHOOK: Output: default@ptestfilter@c=2/d=2
+PREHOOK: query: show partitions ptestfilter
+PREHOOK: type: SHOWPARTITIONS
+POSTHOOK: query: show partitions ptestfilter
+POSTHOOK: type: SHOWPARTITIONS
+c=1/d=2
+c=3/d=1
+c=3/d=2
+PREHOOK: query: drop table ptestfilter
+PREHOOK: type: DROPTABLE
+PREHOOK: Input: default@ptestfilter
+PREHOOK: Output: default@ptestfilter
+POSTHOOK: query: drop table ptestfilter
+POSTHOOK: type: DROPTABLE
+POSTHOOK: Input: default@ptestfilter
+POSTHOOK: Output: default@ptestfilter
-- 
1.7.0.4

