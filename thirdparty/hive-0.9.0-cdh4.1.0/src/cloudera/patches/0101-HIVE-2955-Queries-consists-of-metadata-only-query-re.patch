From ae98629d017ea6057d0e8ba21b69063fa0612c4c Mon Sep 17 00:00:00 2001
From: Namit Jain <namit@apache.org>
Date: Fri, 22 Jun 2012 04:26:59 +0000
Subject: [PATCH 101/148] HIVE-2955 Queries consists of metadata-only-query returns always empty value
 (Navis via namit)

git-svn-id: https://svn.apache.org/repos/asf/hive/trunk@1352771 13f79535-47bb-0310-9956-ffa450edef68
(cherry picked from commit c26d4b71c81dfb8d0c45be317f3d79147ebac935)
---
 .../org/apache/hadoop/hive/ql/exec/ExecDriver.java |    9 ++++++
 .../optimizer/physical/MetadataOnlyOptimizer.java  |    2 +
 ql/src/test/queries/clientpositive/metadataonly1.q |    3 ++
 .../results/clientpositive/metadataonly1.q.out     |   31 ++++++++++++++++++++
 4 files changed, 45 insertions(+), 0 deletions(-)

diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java b/src/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java
index 3ba72b9..6a7268a 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/exec/ExecDriver.java
@@ -60,6 +60,7 @@ import org.apache.hadoop.hive.ql.io.HiveKey;
 import org.apache.hadoop.hive.ql.io.HiveOutputFormat;
 import org.apache.hadoop.hive.ql.io.HiveOutputFormatImpl;
 import org.apache.hadoop.hive.ql.io.IOPrepareCache;
+import org.apache.hadoop.hive.ql.io.OneNullRowInputFormat;
 import org.apache.hadoop.hive.ql.metadata.HiveException;
 import org.apache.hadoop.hive.ql.plan.FetchWork;
 import org.apache.hadoop.hive.ql.plan.FileSinkDesc;
@@ -778,12 +779,14 @@ public class ExecDriver extends Task<MapredWork> implements Serializable, Hadoop
     // The input file does not exist, replace it by a empty file
     Class<? extends HiveOutputFormat> outFileFormat = null;
     boolean nonNative = true;
+    boolean oneRow = false;
     Properties props;
     if (isEmptyPath) {
       PartitionDesc partDesc = work.getPathToPartitionInfo().get(path);
       props = partDesc.getProperties();
       outFileFormat = partDesc.getOutputFileFormatClass();
       nonNative = partDesc.getTableDesc().isNonNative();
+      oneRow = partDesc.getInputFileFormatClass() == OneNullRowInputFormat.class;
     } else {
       TableDesc tableDesc = work.getAliasToPartnInfo().get(alias).getTableDesc();
       props = tableDesc.getProperties();
@@ -841,6 +844,12 @@ public class ExecDriver extends Task<MapredWork> implements Serializable, Hadoop
     String onefile = newPath.toString();
     RecordWriter recWriter = outFileFormat.newInstance().getHiveRecordWriter(job, newFilePath,
         Text.class, false, props, null);
+    if (oneRow) {
+      // empty files are ommited at CombineHiveInputFormat.
+      // for metadata only query, it effectively makes partition columns disappear..
+      // this could be fixed by other methods, but this seemed to be the most easy (HIVEV-2955)
+      recWriter.write(new Text("empty"));  // written via HiveIgnoreKeyTextOutputFormat
+    }
     recWriter.close(false);
     FileInputFormat.addInputPaths(job, onefile);
     return numEmptyPaths;
diff --git a/src/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/MetadataOnlyOptimizer.java b/src/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/MetadataOnlyOptimizer.java
index bf9f18d..46f3f92 100644
--- a/src/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/MetadataOnlyOptimizer.java
+++ b/src/ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/MetadataOnlyOptimizer.java
@@ -34,6 +34,7 @@ import org.apache.hadoop.hive.ql.exec.GroupByOperator;
 import org.apache.hadoop.hive.ql.exec.Operator;
 import org.apache.hadoop.hive.ql.exec.TableScanOperator;
 import org.apache.hadoop.hive.ql.exec.Task;
+import org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat;
 import org.apache.hadoop.hive.ql.lib.DefaultGraphWalker;
 import org.apache.hadoop.hive.ql.lib.DefaultRuleDispatcher;
 import org.apache.hadoop.hive.ql.lib.Dispatcher;
@@ -200,6 +201,7 @@ public class MetadataOnlyOptimizer implements PhysicalPlanResolver {
     private PartitionDesc changePartitionToMetadataOnly(PartitionDesc desc) {
       if (desc != null) {
         desc.setInputFileFormatClass(OneNullRowInputFormat.class);
+        desc.setOutputFileFormatClass(HiveIgnoreKeyTextOutputFormat.class);
         desc.setDeserializerClass(NullStructSerDe.class);
         desc.setSerdeClassName(NullStructSerDe.class.getName());
       }
diff --git a/src/ql/src/test/queries/clientpositive/metadataonly1.q b/src/ql/src/test/queries/clientpositive/metadataonly1.q
index 456e6d8..d97f0d4 100644
--- a/src/ql/src/test/queries/clientpositive/metadataonly1.q
+++ b/src/ql/src/test/queries/clientpositive/metadataonly1.q
@@ -33,3 +33,6 @@ set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;
 
 explain extended select max(ds) from TEST1;
 select max(ds) from TEST1;
+
+select distinct ds from srcpart;
+select min(ds),max(ds) from srcpart;
\ No newline at end of file
diff --git a/src/ql/src/test/results/clientpositive/metadataonly1.q.out b/src/ql/src/test/results/clientpositive/metadataonly1.q.out
index 1bb96a1..1807f0b 100644
--- a/src/ql/src/test/results/clientpositive/metadataonly1.q.out
+++ b/src/ql/src/test/results/clientpositive/metadataonly1.q.out
@@ -1452,3 +1452,34 @@ POSTHOOK: Input: default@test1@ds=1
 POSTHOOK: Input: default@test1@ds=2
 #### A masked pattern was here ####
 2
+PREHOOK: query: select distinct ds from srcpart
+PREHOOK: type: QUERY
+PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
+PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
+PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
+PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
+#### A masked pattern was here ####
+POSTHOOK: query: select distinct ds from srcpart
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
+POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
+POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
+POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
+#### A masked pattern was here ####
+2008-04-08
+2008-04-09
+PREHOOK: query: select min(ds),max(ds) from srcpart
+PREHOOK: type: QUERY
+PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
+PREHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
+PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
+PREHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
+#### A masked pattern was here ####
+POSTHOOK: query: select min(ds),max(ds) from srcpart
+POSTHOOK: type: QUERY
+POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=11
+POSTHOOK: Input: default@srcpart@ds=2008-04-08/hr=12
+POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=11
+POSTHOOK: Input: default@srcpart@ds=2008-04-09/hr=12
+#### A masked pattern was here ####
+2008-04-08	2008-04-09
-- 
1.7.0.4

